---
title: "Main notebook"
output: pdf_document
date: '2023-02-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Acknowledgements

The data and a large portion of data preprocessing is provided by Jane Reid. The re-implementation into INLA is also largely based on the work from Stefanie Muff.

# Data loading

```{r data loading}
library(MCMCglmm)
library(MASS)
library(nadiv)
library(bdsmatrix)
library(INLA)
library(QGglmm)
# library(SMisc)
library(ggplot2)
library(latex2exp)
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!require("GeneticsPed", quietly = TRUE))
    BiocManager::install("GeneticsPed")
if (!require("MCMCglmm", quietly = TRUE))
    install.packages("../MCMCglmm-rbv-patch.tar.gz")

library("GeneticsPed") 
library("MCMCglmm")


qg.data.gg.inds <- read.table("../data/qg.data.gg.inds.steffi.txt", header=T)
d.ped <- ped.prune.inds <- read.table("../data/ped.prune.inds.steffi.txt", header=T)
d.Q <-  read.table("../data/Q.data.steffi.txt", header=T)

qg.data.gg.inds$natalyr.id <- qg.data.gg.inds$natalyr.no

```

Below we do a couple more preprocessing steps

```{r}
# Scale the continuous variances for stability
qg.data.gg.inds$f.coef.sc <- scale(qg.data.gg.inds$f.coef,scale=FALSE)
qg.data.gg.inds$g1.sc <- scale(qg.data.gg.inds$g1,scale=FALSE)
qg.data.gg.inds$natalyr.no.sc <- scale(qg.data.gg.inds$natalyr.no,scale=FALSE)
qg.data.gg.inds$brood.date.sc <- scale(qg.data.gg.inds$brood.date,scale=FALSE)

# Binarize `sex` covariate
qg.data.gg.inds$sex <- qg.data.gg.inds$sex.use.x1 - 1 
```

## Deriving *A*

For INLA we need ids that run from 1 to the number of individuals

```{r}
d.ped <- nadiv::prepPed(d.ped)
d.ped$id <- 1:(nrow(d.ped))

# Maps to keep track of the Ninecode to ID relations
d.map <- d.ped[,c("ninecode","id")]
d.map$g1 <- d.Q[match(d.map$ninecode,d.Q$ninecode),"g1"]
d.map$foc0 <- d.Q[match(d.map$ninecode,d.Q$ninecode),"foc0"]

# Give mother and father the id
d.ped$mother.id <- d.map[match(d.ped$gendam, d.map$ninecode),"id"]
d.ped$father.id <- d.map[match(d.ped$gensire, d.map$ninecode),"id"]

# A can finally be constructed using `nadiv`
Cmatrix <- nadiv::makeAinv(d.ped[,c("id","mother.id","father.id")])$Ainv

# Stores ID twice (to allow for extra IID random effect)

qg.data.gg.inds$id <- d.map[match(qg.data.gg.inds$ninecode, d.map$ninecode), "id"]
qg.data.gg.inds$u <- 1:nrow(qg.data.gg.inds) # Extra IID effect

```


# INLA

The general INLA formula is provided below, where `f()` encode the random effect:

```{r}
FORMULA_EXTRA_IID_NOISE = FALSE # Change this to include iid N(0,1) noise

formula.inla.scaled = surv.ind.to.ad ~ f.coef.sc + g1.sc + natalyr.no.sc + brood.date.sc + sex +
  f(nestrec, model="iid",hyper=list(
    prec=list(initial=log(1/0.05), prior="pc.prec",param=c(1,0.05)) # PC priors
  )) +
  f(natalyr.id, model="iid",hyper=list(
    prec=list(initial=log(1/0.25), prior="pc.prec",param=c(1,0.05)) # PC priors
  )) +
  f(id,model="generic0", # Here we need to specify the covariance matrix 
    Cmatrix=Cmatrix,     #    via the inverse (Cmatrix)
    constr = F, # Doesn't really matter
    hyper=list(
      prec=list(initial=log(1/10), prior="pc.prec",param=c(1,0.05)) # PC priors
     )) +
  ifelse(FORMULA_EXTRA_IID_NOISE,
         f(u, model="iid", constr=T, hyper=list(prec=list(
           initial=log(1),
           fixed=T))
           ),
         0
         )
```

Now we call INLA models (this takes some time). Note that we pass some control arguments to the function call. We compute DIC (Deviance information criterion) for all models with `dic` flag in `control.compute`.  For the binomial models, we want to be able to use `QGglmm` and average over all fixed effects. This is done by supplying the *latent marginal predicted values*, which are not computed unless you pass the `return.marginals.predictor` flag set to true. We also want to set the `CPO` flag to true in the Gaussian model, so we can look a bit at its "residuals" (PIT values). Lastly, the `control.family` argument is used to pass the link functions for binomial models.

```{r}

fit.inla.probit = inla(formula=formula.inla.scaled, family="binomial",
                       data=qg.data.gg.inds,
                       control.compute=list(dic=T, return.marginals.predictor=T),
                       control.family = list(link = "probit"),
)

fit.inla.logit = inla(formula=formula.inla.scaled, family="binomial",
                      data=qg.data.gg.inds,
                      control.compute=list(dic=T, return.marginals.predictor=T),
                      control.family = list(link = "logit"),
)

fit.inla.gaussian = inla(formula=formula.inla.scaled, family="gaussian",
                             data=qg.data.gg.inds,
                             control.compute=list(dic=T, cpo=T) 
)
```




## Residual analyses on Gaussian model

For the Gaussian INLA model we also compute PIT (probability integral transform) values. They resemble the probability that a new response is less than the observed response. Under Gaussian model assumptions, PIT values should be uniformly distributed. [Source](https://julianfaraway.github.io/brinla/examples/chicago.html).


The first plot obviously shows a non-linear trend but rather a sigmoid-like curve. This is interesting!

The second plot shows the fitted values as a function of PIT. Not sure how it should look like, but definitely not like this!

The third plot is the posterior means of the linear predictor for the Gaussian fit versus the same value for the probit model. If we compare logit to probit we see pretty close to a one-to-one correspondance. This is completely violated when comparing the Gaussian one to the two other models.

```{r}
# TODO with these plots: Make them to ggplots instead so it's the same style (aesthethic) for all plots...

# Residual analysis on Gaussian INLA object:)
pit.g = fit.inla.gaussian$cpo$pit

# <Plot 1> Analogous to QQ-plot so should be linear
# --------
plot(
  (1:length(pit.g))/(length(pit.g)+1), sort(pit.g), xlab="Quantiles",
  ylab="Sorted PIT values", main="Sorted PIT values for Gaussian model"
)

# <Plot 2> Posterior mean fitted values as a function of PIT values
# --------    analagous to "Residuals vs fitted"
plot(fit.inla.gaussian$summary.fitted.values$mean, pit.g,
     xlab="Posterior mean fitted values",
     ylab="PIT values", main="Posterior mean vs. PIT values"
     )

# <Plot 3> Mean linear predictor of different models, showing 
# --------    how different predictors for the models are
par(mfrow=c(1,3))
plot(fit.inla.logit$summary.linear.predictor[, 1],
     fit.inla.probit$summary.linear.predictor[, 1],
     main="\nLogit (x) versus Probit (y)", xlab="",ylab=""
)
abline(0,1)
plot(fit.inla.gaussian$summary.linear.predictor[, 1],
     fit.inla.probit$summary.linear.predictor[, 1],
     main="\nGaussian (x) versus Probit (y)", xlab="", ylab=""
)
abline(0,1)
plot(fit.inla.gaussian$summary.linear.predictor[, 1],
     fit.inla.logit$summary.linear.predictor[, 1],
     main="\nGaussian (x) versus Probit (y)", xlab="", ylab=""
)
abline(0,1)
mtext("Mean linear predictor of the different models",
      side = 3, line = -1, outer = TRUE)

# <Plot 4> Plot of 'residuals', i.e. difference in true data and the 
# --------    50% quantile of the fitted values

# Compute residuals from the 50% quantile of fitted values
# Scale residuals by multiplying the square of the precisions? Currently: no scaling
n.obs = length(qg.data.gg.inds$u)
resids = qg.data.gg.inds$surv.ind.to.ad -
  fit.inla.gaussian$summary.fitted.values$`0.5quant`
par(mfrow=c(1,1))
plot(resids, main="Residuals of Gaussian model", ylab="")

# <Plot 5> Recreation of QQ plot using residuals computed above instead of PIT values
qqplot(qnorm(ppoints(n.obs),
             mean = mean(qg.data.gg.inds$surv.ind.to.ad),
             sd = sd(qg.data.gg.inds$surv.ind.to.ad)
             ),
       resids, xlab="Theoretical quantiles", ylab="Sample Quantiles",
       main="Q-Q plot from 'residuals' above")

# <From that thing>
ggplot(data.frame(
  Fittedvalues = fit.inla.gaussian$summary.fitted.values$mean,
  Residuals = resids),
  aes(x=Fittedvalues, y=Residuals)) +
  geom_point() + geom_smooth(se=T) +
  labs(x="Fitted values", title="Violation of linearity assumtption")

```

We define a general method for looking at the results of an INLA model.

```{r}
## This is a nice place to play around
test = fit.inla.logit$marginals.linear.predictor
plot(test$Predictor.2) # 43x2 data for x and y...

inla.posterior.marginal.latent.mode <- function(fit){
  modes = c()
  iter = 1
  for(predictor in names(fit$marginals.linear.predictor)){
    xy = get(predictor, fit$marginals.linear.predictor)
    modes[iter] = xy[, "x"][which.max(xy[, "y"])]
    iter = iter + 1
  }
  modes
}
marginal.latent.samples <- function(fit, nsamples){
  #' TODO : Work in progress!!
  #' TODO : improve runtime, seems like inla.rmarginal takes the longest time.
  #' What if we sample.marginal `nsamples` samples for each predictor
  #' Output is list(c(...), c(...), ..., c(...)) w/ nsamples list elems,
  #' and 2000ish elements in each c() (the different predictor samples)
  out_transpose = matrix(nrow=nsamples)
  firstiter = T
  cat("DEBUG: Entering sampling for loop\n")
  for(predictor in names(fit$marginals.linear.predictor)){
    xy = get(predictor, fit$marginals.linear.predictor)
    predictor_samples = inla.rmarginal(nsamples, xy)
    out_transpose = cbind(out_transpose, predictor_samples)
  }
  # Need to slice off the first NA-column:
  out_transpose = out_transpose[, 2:ncol(out_transpose)]
  cat("DEBUG: Entering transposing loop\n")
  # We want list where each list element is one sample, i.e. the transposed
  # Start naive method, might be optimized:
  out = list()
  for(i in nsamples){
    out$i = out_transpose[i, ]
  }
  out
}
# testing func:
marginal.latent.alternative(fit.inla.logit, 100)

report.max.skewness <- function(posterior){
  #' Made esepcially for marginal linear predictor but should work on any
  #' list containing named "x" and "y" columns
  library(e1071)
  iter = 1
  posterior_skews = c()
  for(predictor in names(posterior)){
    posterior_skews[iter] = skewness(get(predictor, posterior)[, "x"])
    iter = iter + 1
  }
  cat("Minimum skew for list no.", which.min(posterior_skews), "with skewness",
      min(posterior_skews), "and max for list no.", which.max(posterior_skews),
      "with skewness", max(posterior_skews), ".\n")
}

report.max.skewness(test)
plot(test$Predictor.321)


analyze.inla.fit <- function(inla.fit){
  # Collecting diagnostic functions in this method:-)
  #' Check if there is a problem (ok of =0) and dic
  print(paste(inla.fit$mode$mode.status,
  inla.fit$dic$dic))
  
  print(summary(inla.fit))
  
  #inla.fit$summary.hyperpar,
  #inla.fit$summary.fixed,
  
  #inla_mmarginal(inla.fit),
  #inla_emarginal(inla.fit)
  #))
  
  #' Plotting the posterior marginals for the variances; This is a bit cumbersome,
  #' because INLA works with precisions, so we need a transformation. 
  #' The code below does it for us:
  par(mfrow=c(1,3))
  
  plot(inla.tmarginal(
    function(x) 1/x,inla.fit$marginals.hyperpar$`Precision for nestrec`),
    type="l",main = "next")
  
  plot(inla.tmarginal(
    function(x) 1/x,inla.fit$marginals.hyperpar$`Precision for natalyr.id`),
    type="l",main="natalyr")
  
  plot(inla.tmarginal(
    function(x) 1/x,inla.fit$marginals.hyperpar$`Precision for id`),
    type="l",main="animal")
}

# analyze.inla.fit(fit.inla.probit)

```

Below is a method used to obtain posterior distribution of the back-transformed heritability:

```{r}
## Testing with dfs
test = data.frame(va = c(1,2,3), vp = c(4,5,6))
test$predict = list(c(7,8,9), c(10,11,12), c(13,14,15))
# apply(test, 1, function(r) print(r) )

get.h2 <- function(inla.fit, n, use.scale=F, model=NA){
  #' Get n samples of heritability from INLA fit
  #' h^2 computed as reciprocal of precision for id, over the sum of 
  #' (the reciprocal of) all random effects / hyperparameters 
  samples <- inla.hyperpar.sample(n=n,inla.fit)
  denominator = 0
  for(cname in colnames(samples)){ denominator = denominator + 1/samples[, cname]}
  
  if(use.scale){
    # We need model specification to use scale
    stopifnot(model %in% c("binom1.probit", "binom1.logit"))
    scale.param = ifelse(model == "binom1.probit", 1, pi^2/3)
    denominator = denominator + scale.param
  }
  
  h2.inla <- (1/samples[,"Precision for id"]) / denominator
  return(h2.inla)
}

get.h2.from.qgparams <- function(inla.fit, modelname, n, n.obs=nrow(d.ped)){
  #' Computes a posterior of data-scale heritability (h2) using QGParams
  #'  
  #' Params:
  #' inla.fit    the fitted INLA object
  #' modelname  a string specifying model
  #'    ("Gaussian", "binomN1.probit", "binom1.logit")
  #' n.obs      keyword argument if binomial model is has N != 1 trials
  #'    NB: Should explicitly be set to NULL if not relevant (Gaussian model)
  #'    Currently not in use as we're always dealing with binary (1 trial)
  stopifnot(modelname %in% c("Gaussian", "binom1.probit", "binom1.logit"))
  samples.posterior <- inla.hyperpar.sample(n=n,inla.fit)
  vp.samples = 0
  for(cname in colnames(samples.posterior)){
    vp.samples = vp.samples + 1/samples.posterior[, cname]
    }
  mu = inla.fit$summary.fixed$mean[1]
  va.samples = 1/samples.posterior[,"Precision for id"]
  kwargs = list(verbose=F)
  # out = mapply(QGparams, mu, va.samples, vp.samples, modelname, MoreArgs = kwargs)
  h2.getter = function(...){
    get("h2.obs", suppressWarnings(QGparams(...)))
    }
  out = mapply(h2.getter, mu, va.samples, vp.samples, modelname, MoreArgs=kwargs)
  return(out)
}


new.h2.transf <- function(fit, modelname, nsamples){
  # This is very much WIP but works I think now
  posterior.samples = inla.hyperpar.sample(nsamples, fit)
  marginal.mode = inla.posterior.marginal.latent.mode(fit)
  debug_mu = fit$summary.fixed$mean[1]
  vp.samples = 0
  for(cname in colnames(posterior.samples)){
    vp.samples = vp.samples + 1/posterior.samples[, cname]
    }
  df <- data.frame(va = as.vector(1/posterior.samples[, "Precision for id"]),
                   vp = as.vector(vp.samples)
                   )
  cat("Entering new func... ")
  df$predict = marginal.latent.alternative(fit, nsamples)
  cat("New func worked!")
  posterior = do.call("rbind", apply(df, 1, function(row){
    QGparams(predict=row[["predict"]], var.a=row[["va"]], var.p=row[["vp"]],
             model=modelname, verbose=F)
  }))
  posterior
}

## analyze things ran on markov
load("heritabilities_SSH_binom1.logit.Rdata")
par(mfrow=c(2,2))
truehist(heritability_averaged$h2.obs, main="Bayesian",
         xlab=expression(h[obs]^2))
truehist(heritability_frequentist_avged$h2.obs, main="Frequentist",
         xlab=expression(h[obs]^2))
truehist(heritability_notavged, main="No averaging",
         xlab=expression(h[obs]^2))
truehist(scaled.heritability, main="Direct scaling",
         xlab=expression(h[obs]^2))

#' Log (first run)
# Called function at: Sun Feb 26 06:34:01 PM 2023
# Entering `new.h2.transf` (Bayesian sampling)
# Entering new func... DEBUG: Entering sampling for loop
# DEBUG: Entering transposing loop
# New func worked!Done after 1.895322 minutes. Entering same function without the Bayesian stuff.
# Done after 1.875852 minutes. Now without averaging:Done after 8.269284 minutes.
# Saving to disk...
# [1] 0
# Called function at: Sun Feb 26 10:20:25 PM 2023
# Entering `new.h2.transf` (Bayesian sampling)
# Entering new func... DEBUG: Entering sampling for loop
# DEBUG: Entering transposing loop
# New func worked!Done after 4.210027 minutes. Entering same function without the Bayesian stuff.
# Done after 6.657132 minutes. Now without averaging:Done after 3.654567 minutes.
# Saving to disk...
# [1] 0
```

We extend the contents of the INLA fit to include heritabilities on the different scales

```{r}
# Compute h2
n.samples = 10000
fit.inla.gaussian$h2.latent = get.h2(fit.inla.gaussian, n.samples)
fit.inla.logit$h2.latent = get.h2(fit.inla.logit, n.samples)
fit.inla.probit$h2.latent = get.h2(fit.inla.probit, n.samples)

fit.inla.logit$h2.scaled = get.h2(fit.inla.logit, n.samples, use.scale=T,
                                  model="binom1.logit")
fit.inla.probit$h2.scaled = get.h2(fit.inla.probit, n.samples,use.scale=T,
                                   model="binom1.probit")

fit.inla.logit$h2.qgglmm  = get.h2.from.qgparams(fit.inla.logit, "binom1.logit", n.samples)
fit.inla.probit$h2.qgglmm = get.h2.from.qgparams(fit.inla.probit, "binom1.probit", n.samples)
```

Plotting some histograms:

Trying one with all overlapping:

```{r}
df.latent.h2 = data.frame(samples=c(unname(fit.inla.logit$h2.latent), unname(fit.inla.probit$h2.latent)),
                      Model=c(
                        rep("Logit",length(fit.inla.logit$h2.latent)),
                        rep("Probit",length(fit.inla.probit$h2.latent))
                      )
                        )

ggplot(df.latent.h2, aes(x=samples, fill=Model)) +
  geom_density(alpha=0.5) +
  ggtitle("Posterior of latent scale heritability for binomial INLA models") +
  xlab("(Latent-scale) Heritability") +
  ylab("Density")
```

```{r}
df.transformed.h2 = data.frame(
  samples=c(
    unname(fit.inla.logit$h2.qgglmm),
    unname(fit.inla.probit$h2.qgglmm),
    unname(fit.inla.gaussian$h2.latent)
    ),
  Model=c(
    rep("Logit",length(fit.inla.logit$h2.qgglmm)),
    rep("Probit", length(fit.inla.probit$h2.qgglmm)),
    rep("Gaussian (no transformation)",length(fit.inla.gaussian$h2.latent))
    )
  )

ggplot(df.transformed.h2, aes(x=log(samples), fill=Model)) +
  geom_density(alpha=0.5) +
  ggtitle("Posterior of transformed heritability") +
  xlab("(Latent-scale) Log-heritability") +
  ylab("Density")


```

Let's try to make table dynamic:

```{r}
get_mode <- function(vec){
  d = density(vec)
  d$x[which.max(d$y)]
}

model.name = unlist(strsplit("test.hei", "[.]"))[2]


print_one_metric <- function(fit, param, digits){
  cat(
    round(mean(get(param, fit)),digits), " (",
    round(get_mode(get(param, fit)),digits), ")\\newline $\\pm$ ",
    round(sd(get(param,fit)),digits), sep="")
}

print_heritability_table <- function(digits){
  #' `digits` is the number of significant digits
  #' Prints tabularx-table of heritability with posterior mean, posterior mode
  #' and standard deviation. Does it for logit, probit and Gaussian.
  header = cat( "% TABLE FROM R:", format(Sys.time(), "%a %b %d %X %Y"), "\n",
  "\\begin{table}[ht]\\centering\n",
    "\\begin{tabularx}{\\textwidth}{lXXX}\n",
    "\\hline\n",
    " & Binomial logit & Binomial probit & Gaussian  \\\\ \n",
    "\\hline \n"
  )
  main = cat(
    "Latent &", print_one_metric(fit.inla.logit, "h2.latent", digits),
    "&", print_one_metric(fit.inla.probit, "h2.latent", digits),
    "&", print_one_metric(fit.inla.gaussian, "h2.latent", digits),
    "\\\\ \n",
    "Scaled &", print_one_metric(fit.inla.logit, "h2.scaled", digits),
    "&", print_one_metric(fit.inla.probit, "h2.scaled", digits),
    "& --",
    "\\\\ \n",
    "QGglmm &", print_one_metric(fit.inla.logit, "h2.qgglmm", digits),
    "&", print_one_metric(fit.inla.logit, "h2.qgglmm", digits),
    "& -- \n"
  )
  footer = cat("\\end{tabularx}",
               "\\caption{<Insert caption>}",
               "\\label{tab:heritabily gutta}",
               "\\end{table}", sep="\n")

  cat(header, main, footer,sep="\n")
  # # Old attempt trying to make it a bit more flexible
  # out = c()
  # # Deal with latent first
  # out[1] = print_one_metric(fit, "h2.latent", digits)
  # param_names = c("h2.scaled", "h2.qgglmm")
  # for(i in 2:3){
  #   if('fit.inla.gaussian' != deparse(substitute(fit))){
  #     out[i] <- print_one_metric(fit,param_names[i-1], digits)
  #   }
  #   else{
  #     # Special case for Gaussian model since it
  #     # doesn't have any transformed variables
  #     out[i] <- "--"
  #   }
  # }
  # return(cat(out, "\\\\"))
}
print_metrics(4)

```

# Simulation data

```{r}

simulated.heritability <- function(NeNc=0.5, idgen=100, nGen = 9, sigmaA=0.4,
                                   linear.predictor=NA, simulated.formula=NA){
  #' Generate pedigree, fit gaussian (INLA) model and 
  #' Remark: linear.predictor should be a callable and pass (at least) u
  #' 
  #' Input:
  #' NeNc:    Effective/Census population mean, used to determine
  #'          Number of fathers and mothers per generation,
  #' idgen:   Numer of individuals per generation in pedigree
  #' nGen:    Number of generations in pedigree
  #' sigmaA:  Additive genetic variance (to get breeding values)
  #' 
  #' linear.predictor:  Callable function of 'u' (breeding values),
  #'                    Should be centered around 0
  #' simulated.formula: Formula expression using the response name
  #'                    `simulated.response`, param `id` and `Cmatrix`,
  #'                    all of which are defined locally in this method.
  #' Output:
  #' heritability:  Posterior latent heritability samples (no transformation)
  #' summary:       List of mean and quantiles of posterior heritability
  #' p:             Portion of TRUE observations in simulated response
  
  ped0 <- generatePedigree(nId = idgen, nGeneration = nGen, 
                           nFather = idgen * NeNc, nMother = idgen * NeNc)
  # Set correct format for pedigree
  pedigree <- ped0[ , c(1,3,2)]
  names(pedigree) <- c("id", "dam", "sire")
  pedigree <- ped0[ ,1:3]
  
  # Generate random breeding values
  # The following will CRASH if you don't use the patched MCMCglmm package!
  u <- rbv(pedigree, sigmaA)
  
  simulated.d.ped <- nadiv::prepPed(pedigree)
  simulated.Cmatrix <- nadiv::makeAinv(simulated.d.ped)$Ainv 
  
  # Generating "true" y_i
  
  # sigmoid.scale <- function(x) exp(x)/(exp(x)+1)
  # simulated.response <- rbinom(length(u), size=1,
  #                              prob=sigmoid.scale(linear.predictor(u)))
  
  # This assumes mean of \eta_i is 0
  simulated.response <- ifelse(linear.predictor(u) <= 0, 0, 1)
  p = mean(simulated.response) # portion of true responses
  
  # Model fitting LMM for binary trait
  # First reload formula environment to access local variables
  environment(simulated.formula) <- environment()
  simulated.fit.inla = inla(formula=simulated.formula, family="gaussian",
                             data=simulated.d.ped,
                             control.compute=list(dic=T)
                            )
  # Checks for error status in INLA fit,
  stopifnot(simulated.fit.inla$mode$mode.status == 0) # status != 0 is trouble
  
  heritability = get.h2(simulated.fit.inla, 10000) #10k samples should be suff
  list(
    heritability=heritability,
    summary=list(
      mean=mean(heritability), standard.deviation=sd(heritability),
       quantiles=quantile(heritability, probs=c(0.025, 0.5, 0.975))),
    p=p
  )
}



```

Now we try to run it through the model pipeline:

```{r}

simulated.formula = simulated.response ~ f(id,model="generic0",
    Cmatrix=simulated.Cmatrix,
    constr = F, # Shouldn't matter
    hyper=list(
      prec=list(initial=log(1/10), prior="pc.prec",param=c(1,0.05)) # PC priors
    ))

result = simulated.heritability(linear.predictor=function(u) u+rnorm(length(u)),
                       simulated.formula=simulated.formula, sigmaA=0.1)

threshold.scaling.param <- function(p) p*(1-p)/(dnorm(qnorm(p)))^2
threshold.scaled.h2 <- 1/threshold.scaling.param(result$p) * result$heritability
simulation.h2.true <- 10/(10+1) # Based on linear predictor, e.g. sigmaA/(sigmaA+1)
data.frame(True=simulation.h2.true,
           Mean.Threshold.scale = mean(threshold.scaled.h2),
           Confidence.Interval = paste0("(",
                            paste(
                              format(
                                quantile(threshold.scaled.h2,
                                         probs=c(0.025,0.975)),
                                digits=4),
                              collapse=", "),
                            ")"
                            ),
           Latent.Mean = mean(result$summary$mean)
           )

### It doesn't seem like it works so well for larger sigmaA's. Let's quantitatively look into deviation:
plot.h2.deviation <- function(){
  sigmaA.list <- c(1:10 %o% 10^(-3:3)) # Log scale between 10^-3 to 10^3
  deviation = c()
  estimates = c()
  true.vals = c()
  for(sigmaA in sigmaA.list){
    cat(">")
    result = simulated.heritability(
      linear.predictor=function(u) u+rnorm(length(u)),
      simulated.formula=simulated.formula, sigmaA=sigmaA)
    threshold.scaled.h2 <- 1/threshold.scaling.param(result$p) * result$heritability
    simulation.h2.true <- sigmaA/(sigmaA+1) # Based on linear predictor, e.g. sigmaA/(sigmaA+1)
    true.vals = c(true.vals, simulation.h2.true)
    estimates = c(estimates, mean(threshold.scaled.h2))
    deviation = c(deviation, simulation.h2.true-mean(threshold.scaled.h2))
  }
  data.frame(estimates=estimates, deviation=deviation,
             true.vals=true.vals, sigmaA=sigmaA.list)
}
res = plot.h2.deviation()
ggplot(data=res, aes(x=sigmaA)) +
  geom_line(aes(y=true.vals,color="True h^2")) +
  geom_line(aes(y=estimates, color="Fitted h^2")) +
  xlab(TeX("$\\sigma^2$")) + ylab(TeX("$h^2$")) + 
  scale_x_continuous(trans='log10') +
  scale_color_manual(name="True versus fitted heritability",
    breaks=c("True h^2", "Fitted h^2"),
    values = c("True h^2"='darkred', "Fitted h^2"='steelblue')
    )

simulation.hyperparameters <- function(NeNc_list=0.1, sigmaA_list=0.4){
  p = list()
  if(length(NeNc_list) > 1){
    cat("Running simulations for NeNc values, sigmaA is fixed at", sigmaA_list[1])
    for(NeNc in NeNc_list){
      simulation_results = simulated.heritability(
      NeNc=NeNc, idgen= 100, nGen = 10, sigmaA = sigmaA_list,
      linear.predictor = function(u) u+rnorm(length(u)),
      simulated.formula = simulated.formula
      )
      p[[paste0(NeNc)]] = simulation_results$heritability
    }
  }
  else{
    cat("Simulations for sigmaA, NeNc is fixed at", NeNc_list[1])
    for(sigmaA in sigmaA_list){
      cat("(",sigmaA,"),")
      simulation_results = simulated.heritability(
      NeNc=NeNc_list, idgen= 100, nGen = 10, sigmaA = sigmaA,
      linear.predictor = function(u) u+rnorm(length(u)),
      simulated.formula = simulated.formula
      )
      p[[paste0(sigmaA)]] = simulation_results$heritability
    }
  }
  return(p)
}

p = simulation.hyperparameters(NeNc_list = c(0.05, 0.1, 0.25, 0.5))
p2 = simulation.hyperparameters(sigmaA_list=c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75)*100)

par(mfrow=c(2,2))
for(i in names(p)){
  truehist(get(i,p), xlab=paste("NeNc =",i))
  abline(v=0.4)
}
par(mfrow=c(3,2))
for(i in names(p2)){
  truehist(get(i,p2), xlab = paste("sigmaA =", i))
  cat("True h2", as.numeric(i)/(as.numeric(i)+1), "\n")
  # abline(v=i/(as.numeric(i)+1)) # a+e_i, e_i~N
}

```
