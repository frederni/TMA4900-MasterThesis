---
title: "Main notebook"
output:
  pdf_document:
    keep_tex: yes
date: '2023-02-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, eval=FALSE, tidy = TRUE, message = FALSE,
  warning = FALSE, strip.white = TRUE, prompt = FALSE,
  cache = TRUE, size = "scriptsize", fig.align = "center",
  number_sections = FALSE
)
```

# R code acknowledgements

The data and a large portion of data preprocessing is provided by Jane Reid. The re-implementation into INLA is also largely based on the work from Stefanie Muff.

# Data loading

```{r data loading}
if (!require("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}
if (!require("GeneticsPed", quietly = TRUE)) {
  BiocManager::install("GeneticsPed")
}
if (!require("MCMCglmm", quietly = TRUE)) {
  install.packages("../MCMCglmm-rbv-patch.tar.gz")
}
library(MCMCglmm)
library(MASS)
library(nadiv)
library(bdsmatrix)
library(INLA)
library(QGglmm)
library(ggplot2)
library(latex2exp)
library("GeneticsPed")
library("MCMCglmm")


# Plotting libraries and settings
library(cowplot)
library(grid)
library(extrafont)
library(reshape2)
font_import(pattern = "cmunrm.ttf", prompt = F) # LaTeX font
loadfonts(device = "win")
texfont <- "CMU Serif" # Laptop...
# texfont <- "CMUSerif-Roman" # For other computer...
theme_set(theme(text = element_text(family = texfont, size = 14)))

# Dataset import
qg.data.gg.inds <- read.table("../data/qg.data.gg.inds.steffi.txt",
  header = TRUE
)
d.ped <- ped.prune.inds <- read.table("../data/ped.prune.inds.steffi.txt",
  header = TRUE
)
d.Q <- read.table("../data/Q.data.steffi.txt", header = TRUE)

qg.data.gg.inds$natalyr.id <- qg.data.gg.inds$natalyr.no
```

Some global settings:
```{r global variables}
SAVE.PLOT <- TRUE
n.samples <- 10000
FORMULA_EXTRA_IID_NOISE <- FALSE # iid N(0,1) noise in songsparrow formula
```

Below we do a couple more preprocessing steps

```{r data scaling}
# Scale the continuous variances for stability
qg.data.gg.inds$f.coef.sc <- scale(qg.data.gg.inds$f.coef, scale = FALSE)
qg.data.gg.inds$g1.sc <- scale(qg.data.gg.inds$g1, scale = FALSE)
qg.data.gg.inds$natalyr.no.sc <- scale(qg.data.gg.inds$natalyr.no, scale = FALSE)
qg.data.gg.inds$brood.date.sc <- scale(qg.data.gg.inds$brood.date, scale = FALSE)

# Binarize `sex` covariate
qg.data.gg.inds$sex <- qg.data.gg.inds$sex.use.x1 - 1
```

## Deriving *A*

For INLA we need ids that run from 1 to the number of individuals

```{r A matrix}
d.ped <- nadiv::prepPed(d.ped)
d.ped$id <- 1:(nrow(d.ped))

# Maps to keep track of the Ninecode to ID relations
d.map <- d.ped[, c("ninecode", "id")]
d.map$g1 <- d.Q[match(d.map$ninecode, d.Q$ninecode), "g1"]
d.map$foc0 <- d.Q[match(d.map$ninecode, d.Q$ninecode), "foc0"]

# Give mother and father the id
d.ped$mother.id <- d.map[match(d.ped$gendam, d.map$ninecode), "id"]
d.ped$father.id <- d.map[match(d.ped$gensire, d.map$ninecode), "id"]

# A can finally be constructed using `nadiv`
Cmatrix <- nadiv::makeAinv(d.ped[, c("id", "mother.id", "father.id")])$Ainv

# Stores ID twice (to allow for extra IID random effect)

qg.data.gg.inds$id <- d.map[match(qg.data.gg.inds$ninecode, d.map$ninecode), "id"]
qg.data.gg.inds$u <- 1:nrow(qg.data.gg.inds) # Extra IID effect
```


# INLA

The general INLA formula is provided below, where `f()` encode the random effect:

```{r inla forumla}


formula.inla.scaled <- surv.ind.to.ad ~ f.coef.sc + g1.sc + natalyr.no.sc + brood.date.sc + sex +
  f(nestrec, model = "iid", hyper = list(
    prec = list(initial = log(1 / 0.05), prior = "pc.prec", param = c(1, 0.05)) # PC priors
  )) +
  f(natalyr.id, model = "iid", hyper = list(
    prec = list(initial = log(1 / 0.25), prior = "pc.prec", param = c(1, 0.05)) # PC priors
  )) +
  f(id,
    model = "generic0", # Here we need to specify the covariance matrix
    Cmatrix = Cmatrix, #    via the inverse (Cmatrix)
    constr = F, # Doesn't really matter
    hyper = list(
      prec = list(initial = log(1 / 10), prior = "pc.prec", param = c(1, 0.05)) # PC priors
    )
  )
if (FORMULA_EXTRA_IID_NOISE) {
  formula.inla.scaled <- update(
    formula.inla.scaled,
    ~ . + f(u,
      model = "iid", constr = T,
      hyper = list(prec = list(
        initial = log(1),
        fixed = T
      ))
    )
  )
}
```

Now we call INLA models (this takes some time). Note that we pass some control arguments to the function call. We compute DIC (Deviance information criterion) for all models with `dic` flag in `control.compute`.  For the binomial models, we want to be able to use `QGglmm` and average over all fixed effects. This is done by supplying the *latent marginal predicted values*, which are not computed unless you pass the `return.marginals.predictor` flag set to true. We also want to set the `CPO` flag to true in the Gaussian model, so we can look a bit at its "residuals" (PIT values). Lastly, the `control.family` argument is used to pass the link functions for binomial models.

```{r inla fitting}
fit.inla.probit <- inla(
  formula = formula.inla.scaled, family = "binomial",
  data = qg.data.gg.inds,
  control.compute = list(dic = T, return.marginals.predictor = T),
  control.family = list(link = "probit"),
)


fit.inla.gaussian <- inla(
  formula = formula.inla.scaled, family = "gaussian",
  data = qg.data.gg.inds,
  control.compute = list(dic = T, cpo = T)
)

data.frame(
  Gaussian = fit.inla.gaussian$dic$dic,
  Probit = fit.inla.probit$dic$dic, row.names = "Deviance Information Criteria"
)
```
# Latent heritability

```{r naive heritability func}
get.h2 <- function(inla.fit, n, use.scale = F, model = NA, include.fixed = F) {
  #' Get n samples of heritability from INLA fit
  #' h^2 computed as reciprocal of precision for id, over the sum of
  #' (the reciprocal of) all random effects / hyperparameters precisions
  #' Input: INLA object, number of samples, scaling flag and model parameter.
  #' Scaling flag determines if we want latent h^2 (F) or observation-scale,
  #' including the link variance in the binomial models.
  samples <- inla.hyperpar.sample(n = n, inla.fit)
  denominator <- 0
  for (cname in colnames(samples)) {
    denominator <- denominator + 1 / samples[, cname]
  }
  if (include.fixed) {
    # Curerently it just takes the SD instead of sampling,
    # didn't find an easy way to sample fixed effect estimates..
    denominator <- denominator + sum(inla.fit$summary.fixed[, "sd"]^2)
  }

  if (use.scale) {
    scales.dictionary <- list(binom1.probit = 1, binom1.logit = pi^2 / 3, round = 0.25)
    scale.param <- get(model, scales.dictionary)
    denominator <- denominator + scale.param
  }

  h2.inla <- (1 / samples[, "Precision for id"]) / denominator
  return(h2.inla)
}

threshold.scaling.param <- function(p) {
  # h^2_l = threshold.scaling.param * h^2_obs
  p * (1 - p) / (dnorm(qnorm(p)))^2
}

```

# Simulation data

```{r simulation method}
simulated.heritability <- function(NeNc = 0.5, idgen = 100, nGen = 9, sigmaA = 0.8,
                                   linear.predictor = NA, simulated.formula = NA,
                                   dichotomize = "round", pc.prior = NA, probit.model = F) {
  #' Generate pedigree, fit gaussian (INLA) model and
  #' Remark: linear.predictor should be a callable and pass (at least) u
  #'
  #' Input:
  #' NeNc:    Effective/Census population mean, used to determine
  #'          Number of fathers and mothers per generation,
  #' idgen:   Numer of individuals per generation in pedigree
  #' nGen:    Number of generations in pedigree
  #' sigmaA:  Additive genetic variance (to get breeding values)
  #'
  #' linear.predictor:  Callable function of 'u' (breeding values),
  #'                    Should be centered around 0
  #' simulated.formula: Formula expression using the response name
  #'                    `simulated.response`, param `id` and `Cmatrix`,
  #'                    all of which are defined locally in this method.
  #' Output:
  #' heritability:  Posterior latent heritability samples (no transformation)
  #' summary:       List of mean and quantiles of posterior heritability
  #' p:             Portion of TRUE observations in simulated response

  ped0 <- generatePedigree(
    nId = idgen, nGeneration = nGen,
    nFather = idgen * NeNc, nMother = idgen * NeNc
  )
  # Set correct format for pedigree
  pedigree <- ped0[, c(1, 3, 2, 5)]
  names(pedigree) <- c("id", "dam", "sire", "sex")

  # Generate random breeding values
  # The following will CRASH if you don't use the patched MCMCglmm package!
  u <- rbv(pedigree[, c(1, 2, 3)], sigmaA)

  simulated.d.ped <- nadiv::prepPed(pedigree, gender = "sex")
  # TODO not sure if nadiv expects binary (0,1) sex or (1,2)
  simulated.Cmatrix <- nadiv::makeAinv(pedigree[, c(1, 2, 3)])$Ainv

  # Generating "true" y_i

  if (dichotomize == "binom1.logit") {
    sigmoid.scale <- function(x) exp(x) / (exp(x) + 1)
    simulated.response <- rbinom(length(u),
      size = 1,
      prob = sigmoid.scale(linear.predictor(u, simulated.d.ped))
    )
  } else if (dichotomize == "round") {
    # This assumes mean of \eta_i is 0
    simulated.response <- ifelse(linear.predictor(u, simulated.d.ped) <= 0, 0, 1)
  } else {
    stop(paste0(
      "Unknown dichotomization method '", dichotomize, "'. ",
      "Consider using 'binom1.logit' or 'round'."
    ))
  }
  p <- mean(simulated.response) # portion of true responses


  # Model fitting LMM for binary trait
  # First reload formula environment to access local variables
  environment(simulated.formula) <- environment()
  simulated.fit.inla <- inla(
    formula = simulated.formula, family = "gaussian",
    data = simulated.d.ped
  )
  # Checks for error status in INLA fit,
  stopifnot(simulated.fit.inla$mode$mode.status == 0) # status != 0 is trouble
  heritability <- get.h2(simulated.fit.inla, 10000) # 10k samples should be suff

  # Also fit probit if specified
  if (probit.model) {
    fit.probit <- inla(
      formula = simulated.formula, family = "binomial",
      data = simulated.d.ped, control.compute = list(return.marginals.predictor = T)
    )
  } else {
    fit.probit <- NULL
  }
  list(
    heritability = heritability,
    summary = list(
      mean = mean(heritability), standard.deviation = sd(heritability),
      quantiles = quantile(heritability, probs = c(0.025, 0.5, 0.975))
    ),
    p = p,
    simulated.response = simulated.response,
    fit = simulated.fit.inla,
    fit.probit = fit.probit
  )
}
```

Now we try to run it through the model pipeline. Here we try $\eta_i = u_i + \varepsilon_i$ where residuals have variance $V_E=1$.

```{r simulation first result}

simulated.formula <- simulated.response ~  f(id,
  model = "generic0",
  Cmatrix = simulated.Cmatrix,
  constr = F, # Shouldn't matter
  hyper = list(
    prec = list(initial = log(1 / 10), prior = "pc.prec", param = c(1, 0.05)) # PC priors
  )
)

report.simulated.threshold.estimate <- function(
    NeNc, idgen, nGen, sigmaA, linear.predictor, simulated.formula, Vp = NA) {
  stopifnot("Vp required to get true h^2" = !is.na(Vp))
  sim.result <- simulated.heritability(
    NeNc, idgen, nGen, sigmaA,
    linear.predictor, simulated.formula
  )
  threshold.scaled.h2 <- threshold.scaling.param(sim.result$p) *
    sim.result$heritability
  simulation.h2.true <- sigmaA / (Vp)

  data.frame(
    Simulation = c(
      simulation.h2.true,
      mean(threshold.scaled.h2),
      paste0(
        "(",
        paste(
          format(
            quantile(threshold.scaled.h2,
              probs = c(0.025, 0.975)
            ),
            digits = 4
          ),
          collapse = ", "
        ),
        ")"
      ),
      mean(sim.result$summary$mean)
    ),
    row.names = c(
      "True h^2", "Estimated h^2_obs, mean",
      "95% Confidence interval",
      "Estimated latent mean"
    )
  )
}

report.simulated.threshold.estimate(
  NeNc = 0.5, idgen = 100, nGen = 9, sigmaA = 0.05,
  function(u, .) {
    u + rnorm(length(u))
  },
  simulated.formula,
  Vp = 0.05 + 1
)

```

Seems to fit generally well here. Let's quantitatively look into estimates for different $\sigma^2_A$:

## Performance over varying $V_A$

```{r sim over varying V_A}
plot.h2.deviation <- function(dichotomize = "round",
                              title = "Simulation heritability,\ndichotomized with rounding",
                              SAVE.PLOT = T, plot.fn = NA, sigma.scale = "log", lin.pred = NULL,
                              dynamic.priors = F) {
  if (sigma.scale == "log") {
    sigmaA.list <- c(1:10 %o% 10^(-3:3)) # Log scale between 10^-3 to 10^3
  } else if (sigma.scale == "small") { # Linear scale between 10^-3 to 0.259
    sigmaA.list <- seq(0.001, 0.26, by = 0.01)
  } else {
    stop("Unrecognized scale for sigmaA.")
  }
  pc.U.list <- c(rep(10, 10) %o% 10^(-3:3))

  deviation <- c()
  estimates <- c()
  latent <- c()
  true.vals <- c()
  est.CI.u <- c()
  est.CI.l <- c()
  iter_num <- 0
  for (sigmaA in sigmaA.list) {
    cat(">")
    if (dynamic.priors) {
      iter_num <- iter_num + 1
      # PoC: Just base it on current sigmaA
      # TODO use seq_along to enumerate over different lists
      if (sigmaA < 1) {
        pc.prior <- c(1, 0.05)
      } else {
        pc.prior <- c(pc.U.list[iter_num], 0.05)
      }
    } else {
      pc.prior <- c(1, 0.05)
    }

    simulated.formula <- simulated.response ~  f(id,
      model = "generic0",
      Cmatrix = simulated.Cmatrix,
      constr = F, # Shouldn't matter
      hyper = list(
        prec = list(initial = log(sigmaA), prior = "pc.prec", param = pc.prior) # PC priors
      )
    )
    if (is.null(lin.pred)) { # The 'usual' linear predictor
      lin.pred <- function(u, .) u + rnorm(length(u))
    }
    result <- simulated.heritability(
      NeNc = 0.5, idgen = 100, nGen = 9, sigmaA = sigmaA,
      linear.predictor = lin.pred,
      simulated.formula = simulated.formula,
      dichotomize = dichotomize,
      pc.prior = pc.prior
    )

    threshold.scaled.h2 <- threshold.scaling.param(result$p) *
      result$heritability
    # True h^2 is dependent on linear predictor, i.e. sigmaA/(sigmaA+1) here
    simulation.h2.true <- sigmaA / (sigmaA + 1)

    latent <- c(latent, mean(result$heritability))
    true.vals <- c(true.vals, simulation.h2.true)
    estimates.CI <- quantile(threshold.scaled.h2, probs = c(0.025, 0.975))
    estimates <- c(estimates, mean(threshold.scaled.h2))
    deviation <- c(deviation, simulation.h2.true - mean(threshold.scaled.h2))
    est.CI.l <- c(est.CI.l, estimates.CI[1])
    est.CI.u <- c(est.CI.u, estimates.CI[2])
  }
  res <- data.frame(
    estimates = estimates, deviation = deviation,
    true.vals = true.vals, latent = latent,
    est.CI.l = est.CI.l, est.CI.u = est.CI.u,
    sigmaA = sigmaA.list
  )
  # Plotting
  p <- ggplot(data = res, aes(x = sigmaA)) +
    geom_ribbon(aes(ymin = est.CI.l, ymax = est.CI.u), alpha = 0.1) +
    geom_line(aes(y = true.vals, color = "True")) +
    geom_line(aes(y = estimates, color = "Fitted (Threshold scaled)")) +
    geom_line(aes(y = latent, color = "Fitted (observation scale)")) +
    xlab(TeX("$\\sigma_A^2$")) +
    ylab(TeX("$h^2$")) +
    scale_x_log10() +
    scale_color_manual(
      name = title,
      breaks = c(
        "True", "Fitted (Threshold scaled)",
        "Fitted (observation scale)"
      ),
      values = c(
        "True" = "darkred", "Fitted (Threshold scaled)" = "steelblue",
        "Fitted (observation scale)" = "darkgreen"
      )
    )
  if (SAVE.PLOT) {
    ggsave(paste0(
      "../figures/simulation_deviance_",
      if (!is.na(plot.fn)) plot.fn, ".pdf"
    ), p + theme(legend.position = "none"), width = 20, height = 20, units = "cm")
    # Save legend as separate plot
    p.legend <- cowplot::get_legend(p)
    pdf("../figures/simulation_deviance_legend.pdf", width = 7.87402, height = 7.87402)
    grid.newpage()
    grid.draw(p.legend)
    dev.off()
  }
  return(list(res = res, p = p))
}
```

Let's test it out for different values

```{r sim results over V_A}
### Plots for sigmaA in (10^-3, 10^3)

simulation.res <- plot.h2.deviation(plot.fn = "round", SAVE.PLOT = T, dynamic.priors = T)
simulation.res$p

### Plot for small values og sigmaA, but finer grid
simulation2.res <- plot.h2.deviation(
  SAVE.PLOT = T, sigma.scale = "small",
  plot.fn = "small", dynamic.priors = T
)
simulation2.res$p

### Standard plotting with different dichotomization techniques
plot.h2.deviation(
  dichotomize = "binom1.logit",
  title = "Simulation heritability",
  plot.fn = "binom", dynamic.priors = TRUE
)
```


## Without residual in linear predictor
We also check what happens if we rerun with $\eta_i=a_i$, i.e. without residuals on underlying scale. Similar results.

```{r sim without resids}
report.simulated.threshold.estimate(
  0.5, 100, 9, 10, function(u, .) u,
  simulated.formula, 10
)
```

Now we want to look into how A (relatedness matrix) looks like.
```{r relatedness density}
plot.A.matrix <- function(pedigree, title.append = NULL) {
  A.matrix <- nadiv::makeA(pedigree)
  A.diag <- diag(A.matrix)
  plot(A.diag)
  A.nondiag <- A.matrix
  diag(A.nondiag) <- NA
  ggplot(data = data.frame(values = A.nondiag@x)) +
    geom_histogram(aes(x = values, y = ..density..), binwidth = 0.01) +
    labs(
      x = "Relatedness value", y = "Density",
      title = paste0("Off-diagonal values", title.append)
    )
}

# For the simulation data:
ped0 <- generatePedigree(
  nId = 100, nGeneration = 24,
  nFather = 0.5 * 100, nMother = 0.5 * 100
)
pedigree <- ped0[, c(1, 3, 2)]
names(pedigree) <- c("id", "dam", "sire")
simulated.d.ped <- nadiv::prepPed(pedigree)
plot.A.matrix(simulated.d.ped, title.append = ", 24 generation simulation")
if (SAVE.PLOT) ggsave("../figures/relatedness-offdiagonal-sim.pdf", width = 20, height = 20, units = "cm")
# Song sparrow data
plot.A.matrix(d.ped[, c("id", "mother.id", "father.id")], ", Song sparrow data")
if (SAVE.PLOT) ggsave("../figures/relatedness-offdiagonal-songsparrow.pdf", width = 20, height = 20, units = "cm")
```



# Residual analyses on Gaussian model

For the Gaussian INLA model we also compute PIT (probability integral transform) values. They resemble the probability that a new response is less than the observed response. Under Gaussian model assumptions, PIT values should be uniformly distributed. [Source](https://julianfaraway.github.io/brinla/examples/chicago.html).


* The first plot are the sorted PIT values over quantiles, analogous to a Q-Q plot in frequentist data. It shows a clear non-linear trend but rather a sigmoid-like curve.
* The second plot shows the PIT values across the different posterior fitted value means. Here we expect no clear pattern for well-behaved models, which is not the case in our model.
* The third plot is the residuals $y_i - \hat{y_i}$ with 95% credible interval. Here, we see a clear separation of those

```{r gaussian plotting}

pit.g <- fit.inla.gaussian$cpo$pit # PIT-values

# <Plot 1> Analogous to QQ-plot so should be linear
# --------
ggplot(data = data.frame(
  Quantiles = 1:length(pit.g) / (length(pit.g) + 1), PIT = sort(pit.g)
)) +
  geom_point(aes(x = Quantiles, y = PIT)) +
  ggtitle("Sorted PIT values for Gaussian model")
if (SAVE.PLOT) ggsave("../figures/PIT-sorted.pdf")

# <Plot 2> Posterior mean fitted values as a function of PIT values
# --------    analagous to "Residuals vs fitted"

ggplot(
  cbind(fit.inla.gaussian$summary.fitted.values, pit.g),
  aes(x = mean, y = pit.g)
) +
  geom_point() +
  geom_smooth() +
  labs(
    title = "PIT values over posterior mean fitted values",
    x = "Posterior fitted values (mean)",
    y = "PIT value"
  )
if (SAVE.PLOT) ggsave("../figures/PIT-over-fitted.pdf")


# <Plot 3> Plot of 'residuals', i.e. difference in true data and the
# --------    mean of the fitted values
df.resid <- qg.data.gg.inds$surv.ind.to.ad -
  fit.inla.gaussian$summary.fitted.values
rownames(df.resid) <- 1:nrow(df.resid)
df.resid$class <- qg.data.gg.inds$surv.ind.to.ad

ggplot(data = df.resid, aes(x = as.numeric(row.names(df.resid)), y = mean, color = factor(class))) +
  geom_errorbar(aes(ymin = `0.025quant`, ymax = `0.975quant`), color = "darkgrey") +
  geom_point() +
  scale_color_manual(name = "Juvenile survival", values = c("darkred", "steelblue")) +
  labs(title = "Residuals of Gaussian model", x = "Index", y = "Residuals")
if (SAVE.PLOT) ggsave("../figures/Residuals-gaussian.pdf")

```

# Transformations of heritability

Before developing methods for transformed heritability, we need to be able to sample from the marginal fitted values on latent scale.

```{r helper funcs}
marginal.latent.mode <- function(fit) {
  #' Get mode for each marginal linear predictor
  modes <- c()
  iter <- 1
  for (predictor in names(fit$marginals.linear.predictor)) {
    xy <- get(predictor, fit$marginals.linear.predictor)
    modes[iter] <- xy[, "x"][which.max(xy[, "y"])]
    iter <- iter + 1
  }
  modes
}


marginal.latent.samples <- function(fit, nsamples) {
  #' Rather than only using mode for each predictor, we use samples
  #' from its posterior, with nsamples samples.
  #' Output is list of nsamples elements, with each element in the list being
  #' a vector of the predictor size (i.e. number of observations in data)
  out_transpose <- matrix(
    nrow = nsamples,
    ncol = length(fit$marginals.linear.predictor)
  )
  for (i in seq_along(fit$marginals.linear.predictor)) {
    xy <- get(names(fit$marginals.linear.predictor)[i], fit$marginals.linear.predictor)
    out_transpose[, i] <- inla.rmarginal(nsamples, xy)
  }

  # We want list where each list element is one sample, i.e. the transposed
  out <- list()
  for (i in 1:nsamples) {
    out[[i]] <- out_transpose[i, ]
  }
  out
}


report.max.skewness <- function(posterior) {
  #' Made esepcially for marginal linear predictor but should work on any
  #' list containing named "x" and "y" columns
  library(e1071)
  iter <- 1
  posterior_skews <- c()
  for (predictor in names(posterior)) {
    posterior_skews[iter] <- skewness(get(predictor, posterior)[, "x"])
    iter <- iter + 1
  }
  cat(
    "Minimum skew for list no.", which.min(posterior_skews), "with skewness",
    min(posterior_skews), "and max for list no.", which.max(posterior_skews),
    "with skewness", max(posterior_skews), ".\n"
  )
}
```

We can now define methods to obtain heritability on the different scales. The first function computes $h^2$ on latent scale, or using the direct transformation by including link variance in denominator. The second method is more comprehensive and uses the library `QGglmm` to obtain estimates on data scale. So far we've only used `QGglmm` without averaging over fixed effects. This takes considerably more time to process, but we still do that one time to compare the results. Then we compare the heritability on four different scales

* Using 10k samples from the *marginal linear predictor*, and using this to average over
* Grabbing the mode for each *marginal linear predictor*, and passing the mode for each 10k sample
* No averaging, i.e. use intercept value instead.
* Use direct scaling method with link variance.

```{r compute heritability method}
get.h2.from.qgparams <- function(inla.fit,
                                 modelname,
                                 n,
                                 averaging = F,
                                 averaging.mode.only = F) {
  #' Computes a posterior of data-scale heritability (h2) using QGParams
  #'
  #' Params:
  #' inla.fit:  The fitted INLA object
  #' modelname: A string specifying model
  #'    ("Gaussian", "binomN1.probit", "binom1.logit")
  #' n:         Number of samples
  #' averaging: Flag to determine if we want to average over fixed effects
  #' mode.only: Flag to determine if marginal latent should just be mode

  stopifnot(modelname %in% c("Gaussian", "binom1.probit", "binom1.logit"))
  samples.posterior <- inla.hyperpar.sample(n = n, inla.fit)
  vp.samples <- 0
  for (cname in colnames(samples.posterior)) {
    vp.samples <- vp.samples + 1 / samples.posterior[, cname]
  }

  if (!averaging) {
    mu <- inla.fit$summary.fixed$mean[1] # Intercept
    va.samples <- 1 / samples.posterior[, "Precision for id"]
    kwargs <- list(verbose = F)

    h2.getter <- function(...) {
      get("h2.obs", suppressWarnings(QGparams(...)))
    }
    posterior <- mapply(h2.getter, mu, va.samples, vp.samples, modelname, MoreArgs = kwargs)
    return(posterior)
  } else {
    # Average over fixed effects
    debug_mu <- inla.fit$summary.fixed$mean[1]
    vp.samples <- 0
    df <- data.frame(
      va = as.vector(1 / samples.posterior[, "Precision for id"]),
      vp = as.vector(vp.samples)
    )
    if (!averaging.mode.only) {
      # Bayesian approach
      df$predict <- marginal.latent.samples(inla.fit, n)
      
      posterior <- do.call("rbind", apply(df, 1, function(row) {
        QGparams(
          predict = row[["predict"]], var.a = row[["va"]], var.p = row[["vp"]],
          model = modelname, verbose = F
        )
      }))
    } else {
      predict.argument <- marginal.latent.mode(inla.fit)
      posterior <- do.call("rbind", apply(df, 1, function(row) {
        QGparams(
          predict = predict.argument, var.a = row[["va"]], var.p = row[["vp"]],
          model = modelname, verbose = F
        )
      }))
    }
   return(posterior$h2.obs) 
  }

  
}

```

Now we compute the heritability on the different scales - for song sparrow data.

```{r compute h2 application}
# Compute h2
heritability <- data.frame(gaussian = get.h2(fit.inla.gaussian, n.samples))


heritability$probit.latent <- get.h2(fit.inla.probit, n.samples)
heritability$probit.scaled <- get.h2(fit.inla.probit, n.samples,
  use.scale = T,
  model = "binom1.probit"
)
heritability$probit.qgglmm <- get.h2.from.qgparams(
  fit.inla.probit,
  "binom1.probit", n.samples
)
```

Then, compute the 3 different approaches with `QGglmm` (this is quite slow). We also include time estimates here.

```{r compute h2 application part 2}
ti = Sys.time()
h2.psi.sparrow <- data.frame(bayesian=
                       get.h2.from.qgparams(fit.inla.probit, "binom1.probit",
                                        n.samples, averaging = T,
                                        averaging.mode.only = F)
)
cat("\n-\nRuntime for Bayesian:", difftime(Sys.time(), ti,units="secs"),"secs.\n")
ti = Sys.time()
h2.psi.sparrow$frequentist <- get.h2.from.qgparams(fit.inla.probit,
                                                       "binom1.probit",
                                                       n.samples,
                                                       averaging = T,
                                                       averaging.mode.only = T)
cat("\n-\nRuntime for Frequentist:", difftime(Sys.time(), ti,units="secs"),"secs.\n")
ti = Sys.time()
h2.psi.sparrow$noavg <- get.h2.from.qgparams(fit.inla.probit,
                                                       "binom1.probit",
                                                       n.samples,
                                                       averaging = F)
cat("\n-\nRuntime for No averaging:", difftime(Sys.time(), ti,units="secs"),"secs.\n")
h2.psi.sparrow$phi <- heritability$probit.scaled
```

We do the same for simulation
```{r compute h2 simulation}

# We store an instance of a gaussian and probit model with V_A = 1
tmp <- simulated.heritability(
  sigmaA=1, linear.predictor = function(u,.) u+rnorm(length(u)),
  simulated.formula = simulated.formula,
  probit.model = TRUE)
fit.sim.probit <- tmp$fit.probit

ti = Sys.time()
h2.psi.sim1 <- data.frame(bayesian=
                       get.h2.from.qgparams(fit.sim.probit, "binom1.probit",
                                        n.samples, averaging = T,
                                        averaging.mode.only = F)
)
cat("\n-\nRuntime for Bayesian:", difftime(Sys.time(), ti,units="secs"),".\n")
ti = Sys.time()
h2.psi.sim1$frequentist <- get.h2.from.qgparams(fit.sim.probit,
                                                       "binom1.probit",
                                                       n.samples,
                                                       averaging = T,
                                                       averaging.mode.only = T)
cat("\n-\nRuntime for Frequentist:", difftime(Sys.time(), ti,units="secs"),".\n")
ti = Sys.time()
h2.psi.sim1$noavg <- get.h2.from.qgparams(fit.sim.probit,
                                                       "binom1.probit",
                                                       n.samples,
                                                       averaging = F)
cat("\n-\nRuntime for No averaging:", difftime(Sys.time(), ti,units="secs"),".\n")
h2.psi.sim1$phi <- get.h2(fit.sim.probit,n.samples,use.scale=T,model="binom1.probit")

# Also fit for smaller V_A, i.e. 0.1
tmp <- simulated.heritability(
  sigmaA=0.1, linear.predictor = function(u,.) u+rnorm(length(u)),
  simulated.formula = simulated.formula,
  probit.model = TRUE)
# fit.sim.gaussian <- tmp$fit # Might not need this
fit.sim.probit <- tmp$fit.probit

h2.psi.sim2 <- data.frame(bayesian=
                       get.h2.from.qgparams(fit.sim.probit, "binom1.probit",
                                        n.samples, averaging = T,
                                        averaging.mode.only = F)
)
h2.psi.sim2$frequentist <- get.h2.from.qgparams(fit.sim.probit,
                                                       "binom1.probit",
                                                       n.samples,
                                                       averaging = T,
                                                       averaging.mode.only = T)
h2.psi.sim2$noavg <- get.h2.from.qgparams(fit.sim.probit,
                                                       "binom1.probit",
                                                       n.samples,
                                                       averaging = F)
h2.psi.sim2$phi <- get.h2(fit.sim.probit,n.samples,use.scale=T,model="binom1.probit")

```

Let's see how it looks like.
```{r plot h2 qgglmm methods}

plot.qgglmm.heritability <- function(h2.psi, dataset, SAVE.PLOT, plot.title=NA, fn.append=NULL){
  #' Similar function for heritability loaded into memory
  color.map = c(application="Dark2", simulation="Spectral")
  stopifnot(dataset %in% names(color.map))
  p <- ggplot(data=melt(h2.psi)) +
    geom_density(aes(x=value, fill=variable), alpha=0.5) +
    scale_fill_brewer(palette=color.map[dataset],
      labels = c(
        expression(h[Psi]^2 *", Bayesian"),
        expression(h[Psi]^2 *", Frequentist"),
        expression(h[Psi]^2 *", No averaging"),
        expression(h[Phi]^2)
        )
      ) + ylab("Density") + xlab("Heritability") +
    theme(legend.text.align = 0, legend.title=element_blank()) +
    if(!is.na(plot.title)) ggtitle(plot.title)
  
  if(SAVE.PLOT){
    ggsave(paste0("../figures/qgglmm-comparison-",dataset,fn.append,".pdf"),p)
  }
  p
}

plot.qgglmm.heritability(h2.psi.sparrow, "application",
                         SAVE.PLOT, plot.title="Application")
plot.qgglmm.heritability(h2.psi.sim1, "simulation",
                         SAVE.PLOT, plot.title=TeX("Simulation, $\\sigma^2_A=1$"),
                         fn.append="va1")
plot.qgglmm.heritability(h2.psi.sim2, "simulation",
                         SAVE.PLOT, plot.title=TeX("Simulation, $\\sigma^2_A=0.1$"),
                         fn.append="va0.1")


```
## Compare different scales

Method to export heritability estimates in a TeX table

```{r print latex table}
get_mode <- function(vec) {
  d <- density(vec)
  d$x[which.max(d$y)]
}


print_one_metric <- function(fit, param, digits) {
  paste(
    round(mean(get(param, fit)), digits), " (",
    round(get_mode(get(param, fit)), digits), ")\\newline $\\pm$ ",
    round(sd(get(param, fit)), digits),
    sep = ""
  )
}

print_heritability_table <- function(digits) {
  #' `digits` is the number of significant digits
  #' Prints tabularx-table of heritability with posterior mean, posterior mode
  #' and standard deviation. Does it for logit, probit and Gaussian.
  header <- paste(
    "% TABLE FROM R:", format(Sys.time(), "%a %b %d %X %Y"), "\n",
    "\\begin{table}[ht]\\centering\n",
    "\\begin{tabularx}{\\textwidth}{lXX}\n",
    "\\hline\n",
    " & Binomial probit & Gaussian  \\\\ \n",
    "\\hline \n"
  )
  main <- paste(
    "Latent &", print_one_metric(heritability, "probit.latent", digits),
    "&", print_one_metric(heritability, "gaussian", digits),
    "\\\\ \n",
    "Scaled &", print_one_metric(heritability, "probit.scaled", digits),
    "& --",
    "\\\\ \n",
    "QGglmm &", print_one_metric(heritability, "probit.qgglmm", digits),
    "& -- \n"
  )
  footer <- paste("\\end{tabularx}",
    "\\caption{<Insert caption>}",
    "\\label{tab:heritabily means}",
    "\\end{table}",
    sep = "\n"
  )

  cat(header, main, footer, sep = "\n")
}
print_heritability_table(4)
```
The table gives some indication, but we also want to look qualitatively on the densities. We start by just plotting a grid to compare each Gaussian vs. Probit scale two by two. First, we fit the simulation probit model and get simulation-based heritability on all scales.

```{r liability estimates}

heritability$gaussian.liability <- threshold.scaling.param(
  mean(qg.data.gg.inds$surv.ind.to.ad)
) * heritability$gaussian
simulation.res2 <- simulated.heritability(0.5, 100, 9,
  sigmaA = 0.5,
  linear.predictor = function(u, .) u + rnorm(length(u)),
  simulated.formula = simulated.formula,
  probit.model = TRUE
)
heritability.sim <- data.frame(
  gaussian = simulation.res2$heritability,
  probit.latent = get.h2(simulation.res2$fit.probit, 10000),
  probit.scaled = get.h2(simulation.res2$fit.probit, 10000, TRUE, "binom1.probit"),
  probit.qgglmm = get.h2.from.qgparams(
    simulation.res2$fit.probit, "binom1.probit",
    10000
  )
)
heritability.sim$gaussian.liability <- threshold.scaling.param(simulation.res2$p) *
  heritability.sim$gaussian

```

```{r grid plotting}
plot_grid_of_heritability <- function(heritability, SAVE.PLOT, plot.fn, colorscheme = NA) {
  p1 <- ggplot() +
    geom_density(data = melt(heritability[, c("gaussian", "probit.latent")]), aes(x = value, fill = variable), alpha = 0.5) +
    theme(legend.position = "none", axis.title = element_blank()) +
    labs(title = TeX("$h^2_{obs}$ vs. $h^2_{lat}$")) +
    if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
  p2 <- ggplot() +
    geom_density(data = melt(heritability[, c("gaussian.liability", "probit.latent")]), aes(x = value, fill = variable), alpha = 0.5) +
    theme(legend.position = "none", axis.title = element_blank()) +
    labs(title = TeX("$h^2_{liab}$ vs. $h^2_{lat}$")) +
    if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
  p3 <- ggplot() +
    geom_density(data = melt(heritability[, c("gaussian", "probit.qgglmm")]), aes(x = value, fill = variable), alpha = 0.5) +
    theme(legend.position = "none", axis.title = element_blank()) +
    labs(title = TeX("$h^2_{obs}$ vs. $h^2_{\\Psi}$")) +
    if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
  p4 <- ggplot() +
    geom_density(data = melt(heritability[, c("gaussian.liability", "probit.qgglmm")]), aes(x = value, fill = variable), alpha = 0.5) +
    theme(legend.position = "none", axis.title = element_blank()) +
    labs(title = TeX("$h^2_{liab}$ vs. $h^2_{\\Psi}$")) +
    if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
  p5 <- ggplot() +
    geom_density(data = melt(heritability[, c("gaussian", "probit.scaled")]), aes(x = value, fill = variable), alpha = 0.5) +
    theme(legend.position = "none", axis.title = element_blank()) +
    labs(title = TeX("$h^2_{obs}$ vs. $h^2_{\\Phi}$")) +
    if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
  p6 <- ggplot() +
    geom_density(data = melt(heritability[, c("gaussian.liability", "probit.scaled")]), aes(x = value, fill = variable), alpha = 0.5) +
    theme(legend.position = "none", axis.title = element_blank()) +
    labs(title = TeX("$h^2_{liab}$ vs. $h^2_{\\Phi}$")) +
    if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
  p <- plot_grid(p1, p3, p5, p2, p4, p6, ggplot() +
      theme_void(),
    get_legend(
      ggplot(data.frame(v = c("Gaussian", "Probit"), x = c(0, 0))) +
        geom_density(aes(x = x, fill = v), alpha = 0.5) +
        scale_fill_discrete(breaks = c("Gaussian", "Probit")) +
        theme(legend.title = element_blank()) +
        if (!is.na(colorscheme)) scale_fill_brewer(palette = colorscheme)
    ),
    axis="tblr"
  )
  if (SAVE.PLOT) ggsave(paste0("../figures/", plot.fn), p)
  list(p1=p1,p2=p2,p3=p3,p4=p4,p5=p5,p6=p6)
  #p # TODO old
}
plot.h2.appl <- plot_grid_of_heritability(heritability, SAVE.PLOT, "grid_application_gaussian_vs_binom.pdf", "Dark2")
# For simulation:
plot.h2.sim <- plot_grid_of_heritability(heritability.sim, SAVE.PLOT, "grid_simulation_gaussian_vs_binom.pdf", "Spectral")
```

Key takeaways:
- The Gaussian model to liability scale doesn't fit well with the other latent models.
- The scalings from binomial latent onto data scale fit well with the Gaussian one

The ones we really care about, is plot $(1,2)$ (p3) and $(2,3)$ (p6), so let's extract them in particular

```{r key plots heritability scales}
plot.h2.appl$p3 +
  theme(legend.position = "right",legend.title = element_blank()) +
  scale_fill_brewer(palette="Dark2",labels = c("Gaussian", "Probit"))
if(SAVE.PLOT) ggsave("../figures/heritability_application_obsscale.pdf")
plot.h2.appl$p6 +
  theme(legend.position = "right",legend.title = element_blank()) +
  scale_fill_brewer(palette="Dark2",labels = c("Gaussian", "Probit"))
if(SAVE.PLOT) ggsave("../figures/heritability_application_liabscale.pdf")

plot.h2.sim$p3 +
  theme(legend.position = "right",legend.title = element_blank()) +
  scale_fill_brewer(palette="Spectral",labels = c("Gaussian", "Probit"))
if(SAVE.PLOT) ggsave("../figures/heritability_simulation_obsscale.pdf")
plot.h2.sim$p6 +
  theme(legend.position = "right",legend.title = element_blank()) +
  scale_fill_brewer(palette="Spectral",labels = c("Gaussian", "Probit"))
if(SAVE.PLOT) ggsave("../figures/heritability_simulation_liabscale.pdf")
```
# Fixed effects for simulation

Okay, let's try to add sex covariate to linear predictor:

```{r fixed effects simulation}

linear_predictor_fixedeffects <- function(u, simulated.d.ped) {
  out <- c()
  intercept <- -0.25
  residuals <- rnorm(length(u))
  simulated.d.ped$sex <- simulated.d.ped$sex - 1
  for (idx in seq_along(u)) {
    out <- c(
      out,
      intercept + 100 * simulated.d.ped$sex[idx] + u[idx] + residuals[idx]
    )
  }
  out
}

report.simulated.threshold.estimate(
  NeNc = 0.5, idgen = 100, nGen = 9, sigmaA = 0.2,
  linear_predictor_fixedeffects,
  simulated.formula,
  Vp = 0.2 + 1 # excluding fixed effects variance
)

m <- plot.h2.deviation(
  dichotomize = "round", title = "Simulation over fixed effects",
  SAVE.PLOT = F, plot.fn = "fixedeffects", sigma.scale = "log",
  lin.pred = linear_predictor_fixedeffects
)
m$p
```

For sufficiently large choice of $\beta$ corresponding to sex, we get progressively worse results as is expected.
