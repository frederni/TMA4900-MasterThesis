---
title: "Main notebook"
output: pdf_document
date: '2023-02-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Acknowledgements

The data and a large portion of data preprocessing is provided by Jane Reid. The re-implementation into INLA is also largely based on the work from Stefanie Muff.

# Data loading

```{r data loading}
library(MCMCglmm)
library(MASS)
library(nadiv)
library(bdsmatrix)
library(INLA)
library(QGglmm)
# library(SMisc)
library(ggplot2)
library(latex2exp)
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!require("GeneticsPed", quietly = TRUE))
    BiocManager::install("GeneticsPed")
if (!require("MCMCglmm", quietly = TRUE))
    install.packages("../MCMCglmm-rbv-patch.tar.gz")

library("GeneticsPed") 
library("MCMCglmm")


qg.data.gg.inds <- read.table("../data/qg.data.gg.inds.steffi.txt", header=T)
d.ped <- ped.prune.inds <- read.table("../data/ped.prune.inds.steffi.txt", header=T)
d.Q <-  read.table("../data/Q.data.steffi.txt", header=T)

qg.data.gg.inds$natalyr.id <- qg.data.gg.inds$natalyr.no

```

Below we do a couple more preprocessing steps

```{r}
# Scale the continuous variances for stability
qg.data.gg.inds$f.coef.sc <- scale(qg.data.gg.inds$f.coef,scale=FALSE)
qg.data.gg.inds$g1.sc <- scale(qg.data.gg.inds$g1,scale=FALSE)
qg.data.gg.inds$natalyr.no.sc <- scale(qg.data.gg.inds$natalyr.no,scale=FALSE)
qg.data.gg.inds$brood.date.sc <- scale(qg.data.gg.inds$brood.date,scale=FALSE)

# Binarize `sex` covariate
qg.data.gg.inds$sex <- qg.data.gg.inds$sex.use.x1 - 1 
```

## Deriving *A*

For INLA we need ids that run from 1 to the number of individuals

```{r}
d.ped <- nadiv::prepPed(d.ped)
d.ped$id <- 1:(nrow(d.ped))

# Maps to keep track of the Ninecode to ID relations
d.map <- d.ped[,c("ninecode","id")]
d.map$g1 <- d.Q[match(d.map$ninecode,d.Q$ninecode),"g1"]
d.map$foc0 <- d.Q[match(d.map$ninecode,d.Q$ninecode),"foc0"]

# Give mother and father the id
d.ped$mother.id <- d.map[match(d.ped$gendam, d.map$ninecode),"id"]
d.ped$father.id <- d.map[match(d.ped$gensire, d.map$ninecode),"id"]

# A can finally be constructed using `nadiv`
Cmatrix <- nadiv::makeAinv(d.ped[,c("id","mother.id","father.id")])$Ainv

# Stores ID twice (to allow for extra IID random effect)

qg.data.gg.inds$id <- d.map[match(qg.data.gg.inds$ninecode, d.map$ninecode), "id"]
qg.data.gg.inds$u <- 1:nrow(qg.data.gg.inds) # Extra IID effect

```


# INLA

The general INLA formula is provided below, where `f()` encode the random effect:

```{r}
FORMULA_EXTRA_IID_NOISE = FALSE # Change this to include iid N(0,1) noise

formula.inla.scaled = surv.ind.to.ad ~ f.coef.sc + g1.sc + natalyr.no.sc + brood.date.sc + sex +
  f(nestrec, model="iid",hyper=list(
    prec=list(initial=log(1/0.05), prior="pc.prec",param=c(1,0.05)) # PC priors
  )) +
  f(natalyr.id, model="iid",hyper=list(
    prec=list(initial=log(1/0.25), prior="pc.prec",param=c(1,0.05)) # PC priors
  )) +
  f(id,model="generic0", # Here we need to specify the covariance matrix 
    Cmatrix=Cmatrix,     #    via the inverse (Cmatrix)
    constr = F, # Doesn't really matter
    hyper=list(
      prec=list(initial=log(1/10), prior="pc.prec",param=c(1,0.05)) # PC priors
     )) 
if(FORMULA_EXTRA_IID_NOISE){
  formula.inla.scaled = update(formula.inla.scaled,
                               ~ . + f(u, model="iid", constr=T,
                                       hyper=list(prec=list(
                                         initial=log(1),
                                         fixed=T))
                                       )
                               )
}
```

Now we call INLA models (this takes some time). Note that we pass some control arguments to the function call. We compute DIC (Deviance information criterion) for all models with `dic` flag in `control.compute`.  For the binomial models, we want to be able to use `QGglmm` and average over all fixed effects. This is done by supplying the *latent marginal predicted values*, which are not computed unless you pass the `return.marginals.predictor` flag set to true. We also want to set the `CPO` flag to true in the Gaussian model, so we can look a bit at its "residuals" (PIT values). Lastly, the `control.family` argument is used to pass the link functions for binomial models.

```{r}

fit.inla.probit = inla(formula=formula.inla.scaled, family="binomial",
                       data=qg.data.gg.inds,
                       control.compute=list(dic=T, return.marginals.predictor=T),
                       control.family = list(link = "probit"),
)

fit.inla.logit = inla(formula=formula.inla.scaled, family="binomial",
                      data=qg.data.gg.inds,
                      control.compute=list(dic=T, return.marginals.predictor=T),
                      control.family = list(link = "logit"),
)

fit.inla.gaussian = inla(formula=formula.inla.scaled, family="gaussian",
                             data=qg.data.gg.inds,
                             control.compute=list(dic=T, cpo=T) 
)
```




## Residual analyses on Gaussian model

For the Gaussian INLA model we also compute PIT (probability integral transform) values. They resemble the probability that a new response is less than the observed response. Under Gaussian model assumptions, PIT values should be uniformly distributed. [Source](https://julianfaraway.github.io/brinla/examples/chicago.html).


* The first plot are the sorted PIT values over quantiles, analogous to a Q-Q plot in frequentist data. It shows a clear non-linear trend but rather a sigmoid-like curve.
* The second plot shows the PIT values across the different posterior fitted value means. Here we expect no clear pattern for well-behaved models, which is not the case in our model.
* The third plot is the residuals $y_i - \hat{y_i}$ with 95% credible interval. Here, we see a clear separation of those

```{r gaussian plotting}

pit.g = fit.inla.gaussian$cpo$pit # PIT-values

# <Plot 1> Analogous to QQ-plot so should be linear
# --------
ggplot(data=data.frame(
  Quantiles=1:length(pit.g)/(length(pit.g)+1), PIT=sort(pit.g))) +
  geom_point(aes(x=Quantiles, y=PIT)) + ggtitle("Sorted PIT values for Gaussian model")

# <Plot 2> Posterior mean fitted values as a function of PIT values
# --------    analagous to "Residuals vs fitted"
ggplot(cbind(fit.inla.gaussian$summary.fitted.values, pit.g),
       aes(x=mean, y=pit.g)) +
  geom_point() +
  geom_smooth() +
  labs(title="PIT values over posterior mean fitted values",
                      x="Posterior fitted values (mean)",
                      y="PIT value")

# <Plot 3> Mean linear predictor of different models, showing 
# --------    how different predictors for the models are. Not in use.
plot.inla.linear.predictors <- function(){
  par(mfrow=c(1,3))
  plot(fit.inla.logit$summary.linear.predictor[, 1],
       fit.inla.probit$summary.linear.predictor[, 1],
       main="\nLogit (x) versus Probit (y)", xlab="",ylab=""
  )
  abline(0,1)
  plot(fit.inla.gaussian$summary.linear.predictor[, 1],
       fit.inla.probit$summary.linear.predictor[, 1],
       main="\nGaussian (x) versus Probit (y)", xlab="", ylab=""
  )
  abline(0,1)
  plot(fit.inla.gaussian$summary.linear.predictor[, 1],
       fit.inla.logit$summary.linear.predictor[, 1],
       main="\nGaussian (x) versus Probit (y)", xlab="", ylab=""
  )
  abline(0,1)
  mtext("Mean linear predictor of the different models",
        side = 3, line = -1, outer = TRUE)
}


# <Plot 4> Plot of 'residuals', i.e. difference in true data and the 
# --------    mean of the fitted values

df.resid = qg.data.gg.inds$surv.ind.to.ad - 
  fit.inla.gaussian$summary.fitted.values
rownames(df.resid) = 1:nrow(df.resid)
df.resid$class = qg.data.gg.inds$surv.ind.to.ad

ggplot(data=df.resid, aes(x=as.numeric(row.names(df.resid)), y=mean, color=factor(class))) +
  geom_errorbar(aes(ymin=`0.025quant`, ymax=`0.975quant`), color="darkgrey") +
  geom_point() + scale_color_manual(name="Juvenile survival", values=c("darkred", "steelblue")) +
  labs(title="Residuals of Gaussian model", x="Index", y="Residuals")


# <Plot 5> Recreation of QQ plot using residuals computed above instead of PIT values
#           Unused
plot.inla.qqplot <- function(){
  n.obs = length(qg.data.gg.inds$u)
qqplot(qnorm(ppoints(n.obs),
             mean = mean(qg.data.gg.inds$surv.ind.to.ad),
             sd = sd(qg.data.gg.inds$surv.ind.to.ad)
             ),
       resids, xlab="Theoretical quantiles", ylab="Sample Quantiles",
       main="Q-Q plot from 'residuals' above")  
}

```
## Transformations of heritability

Before developing methods for transformed heritability, we need to be able to sample from the marginal fitted values on latent scale.

```{r}

marginal.latent.mode <- function(fit){
  #' Get mode for each marginal linear predictor
  modes = c()
  iter = 1
  for(predictor in names(fit$marginals.linear.predictor)){
    xy = get(predictor, fit$marginals.linear.predictor)
    modes[iter] = xy[, "x"][which.max(xy[, "y"])]
    iter = iter + 1
  }
  modes
}


marginal.latent.samples <- function(fit, nsamples){
  #' Rather than only using mode for each predictor, we use samples
  #' from its posterior, with _nsamples_ samples. 
  #' Output is list of _nsamples_ elements, with each element in the list being
  #' a vector of the predictor size (i.e. number of observations in data)
  out_transpose = matrix(nrow=nsamples,
                         ncol=length(fit$marginals.linear.predictor))
  for(i in seq_along(fit$marginals.linear.predictor)){
    xy = get(names(fit$marginals.linear.predictor)[i], fit$marginals.linear.predictor)
    out_transpose[, i] = inla.rmarginal(nsamples, xy)
  }

  # We want list where each list element is one sample, i.e. the transposed
  out = list()
  for(i in 1:nsamples){
    out[[i]] = out_transpose[i, ]
  }
  out
}


report.max.skewness <- function(posterior){
  #' Made esepcially for marginal linear predictor but should work on any
  #' list containing named "x" and "y" columns
  library(e1071)
  iter = 1
  posterior_skews = c()
  for(predictor in names(posterior)){
    posterior_skews[iter] = skewness(get(predictor, posterior)[, "x"])
    iter = iter + 1
  }
  cat("Minimum skew for list no.", which.min(posterior_skews), "with skewness",
      min(posterior_skews), "and max for list no.", which.max(posterior_skews),
      "with skewness", max(posterior_skews), ".\n")
}


```

We can now define methods to obtain heritability on the different scales

```{r}

get.h2 <- function(inla.fit, n, use.scale=F, model=NA){
  #' Get n samples of heritability from INLA fit
  #' h^2 computed as reciprocal of precision for id, over the sum of 
  #' (the reciprocal of) all random effects / hyperparameters precisions
  #' Input: INLA object, number of samples, scaling flag and model parameter.
  #' Scaling flag determines if we want latent h^2 (F) or observation-scale,
  #' including the link variance in the binomial models.
  samples <- inla.hyperpar.sample(n=n,inla.fit)
  denominator = 0
  for(cname in colnames(samples)){ denominator = denominator + 1/samples[, cname]}
  
  if(use.scale){
    # We need model specification to use scale
    stopifnot(model %in% c("binom1.probit", "binom1.logit"))
    scale.param = ifelse(model == "binom1.probit", 1, pi^2/3)
    denominator = denominator + scale.param
  }
  
  h2.inla <- (1/samples[,"Precision for id"]) / denominator
  return(h2.inla)
}

get.h2.from.qgparams <- function(inla.fit, 
                                 modelname, 
                                 n, 
                                 averaging=F,
                                 averaging.mode.only=F){
  #' Computes a posterior of data-scale heritability (h2) using QGParams
  #'
  #' Params:
  #' inla.fit:  The fitted INLA object
  #' modelname: A string specifying model
  #'    ("Gaussian", "binomN1.probit", "binom1.logit")
  #' n:         Number of samples  
  #' averaging: Flag to determine if we want to average over fixed effects
  #' mode.only: Flag to determine if marginal latent should just be mode

  stopifnot(modelname %in% c("Gaussian", "binom1.probit", "binom1.logit"))
  samples.posterior <- inla.hyperpar.sample(n=n,inla.fit)
  vp.samples = 0
  for(cname in colnames(samples.posterior)){
    vp.samples = vp.samples + 1/samples.posterior[, cname]
  }
  
  if(! averaging){
    mu = inla.fit$summary.fixed$mean[1] # Intercept
    va.samples = 1/samples.posterior[,"Precision for id"]
    kwargs = list(verbose=F)
  
    h2.getter = function(...){
      get("h2.obs", suppressWarnings(QGparams(...)))
      }
    posterior = mapply(h2.getter, mu, va.samples, vp.samples, modelname, MoreArgs=kwargs)
  }
  else{
    # Average over fixed effects
    debug_mu = fit$summary.fixed$mean[1]
    vp.samples = 0
    df <- data.frame(va = as.vector(1/posterior.samples[, "Precision for id"]),
                     vp = as.vector(vp.samples)
                     )
    if(! averaging.mode.only){
      df$predict = marginal.latent.samples(fit, nsamples)
      posterior = do.call("rbind", apply(df, 1, function(row){
        QGparams(predict=row[["predict"]], var.a=row[["va"]], var.p=row[["vp"]],
                 model=modelname, verbose=F)
      }))
    }
    else{
      predict.argument = marginal.latent.mode(inla.fit)
      posterior = do.call("rbind", apply(df, 1, function(r){
        QGparams(predict=predict.argument, var.a=row[["va"]], var.p=row[["vp"]],
                 model=modelname, verbose=F)
      }))
    }
  }
  
  return(posterior)
}

## analyze things ran on markov
load("heritabilities_SSH_binom1.logit.Rdata")
par(mfrow=c(2,2))
truehist(heritability_averaged$h2.obs, main="Bayesian",
         xlab=expression(h[obs]^2))
truehist(heritability_frequentist_avged$h2.obs, main="Frequentist",
         xlab=expression(h[obs]^2))
truehist(heritability_notavged, main="No averaging",
         xlab=expression(h[obs]^2))
truehist(scaled.heritability, main="Direct scaling",
         xlab=expression(h[obs]^2))
load("heritabilities_SSH_binom1.probit.Rdata")
truehist(heritability_averaged$h2.obs, main="Bayesian",
         xlab=expression(h[obs]^2))
truehist(heritability_frequentist_avged$h2.obs, main="Frequentist",
         xlab=expression(h[obs]^2))
truehist(heritability_notavged, main="No averaging",
         xlab=expression(h[obs]^2))
truehist(scaled.heritability, main="Direct scaling",
         xlab=expression(h[obs]^2))

#' Log (first run) TODO update with log stored in Laptop TMUX session 0
# Called function at: Sun Feb 26 06:34:01 PM 2023
# Entering `new.h2.transf` (Bayesian sampling)
# Entering new func... DEBUG: Entering sampling for loop
# DEBUG: Entering transposing loop
# New func worked!Done after 1.895322 minutes. Entering same function without the Bayesian stuff.
# Done after 1.875852 minutes. Now without averaging:Done after 8.269284 minutes.
# Saving to disk...
# [1] 0
# Called function at: Sun Feb 26 10:20:25 PM 2023
# Entering `new.h2.transf` (Bayesian sampling)
# Entering new func... DEBUG: Entering sampling for loop
# DEBUG: Entering transposing loop
# New func worked!Done after 4.210027 minutes. Entering same function without the Bayesian stuff.
# Done after 6.657132 minutes. Now without averaging:Done after 3.654567 minutes.
# Saving to disk...
# [1] 0
```

We extend the contents of the INLA fit to include heritabilities on the different scales

```{r}
# Compute h2
# TODO consider changing this to rather be stored in data.frame, this method is
#       difficult to handle..
n.samples = 10000
fit.inla.gaussian$h2.latent = get.h2(fit.inla.gaussian, n.samples)
fit.inla.logit$h2.latent = get.h2(fit.inla.logit, n.samples)
fit.inla.probit$h2.latent = get.h2(fit.inla.probit, n.samples)

fit.inla.logit$h2.scaled = get.h2(fit.inla.logit, n.samples, use.scale=T,
                                  model="binom1.logit")
fit.inla.probit$h2.scaled = get.h2(fit.inla.probit, n.samples,use.scale=T,
                                   model="binom1.probit")

fit.inla.logit$h2.qgglmm  = get.h2.from.qgparams(fit.inla.logit, "binom1.logit", n.samples)
fit.inla.probit$h2.qgglmm = get.h2.from.qgparams(fit.inla.probit, "binom1.probit", n.samples)
```

Plotting some histograms:

Trying one with all overlapping:

```{r}
df.latent.h2 = data.frame(samples=c(unname(fit.inla.logit$h2.latent), unname(fit.inla.probit$h2.latent)),
                      Model=c(
                        rep("Logit",length(fit.inla.logit$h2.latent)),
                        rep("Probit",length(fit.inla.probit$h2.latent))
                      )
                        )

ggplot(df.latent.h2, aes(x=samples, fill=Model)) +
  geom_density(alpha=0.5) +
  ggtitle("Posterior of latent scale heritability for binomial INLA models") +
  xlab("(Latent-scale) Heritability") +
  ylab("Density")
```

```{r}
df.transformed.h2 = data.frame(
  samples=c(
    unname(fit.inla.logit$h2.qgglmm),
    unname(fit.inla.probit$h2.qgglmm),
    unname(fit.inla.gaussian$h2.latent)
    ),
  Model=c(
    rep("Logit",length(fit.inla.logit$h2.qgglmm)),
    rep("Probit", length(fit.inla.probit$h2.qgglmm)),
    rep("Gaussian (no transformation)",length(fit.inla.gaussian$h2.latent))
    )
  )

ggplot(df.transformed.h2, aes(x=log(samples), fill=Model)) +
  geom_density(alpha=0.5) +
  ggtitle("Posterior of transformed heritability") +
  xlab("(Latent-scale) Log-heritability") +
  ylab("Density")


```

Method to export heritability estimates in a TeX table

```{r}
get_mode <- function(vec){
  d = density(vec)
  d$x[which.max(d$y)]
}

model.name = unlist(strsplit("test.hei", "[.]"))[2]


print_one_metric <- function(fit, param, digits){
  paste(
    round(mean(get(param, fit)),digits), " (",
    round(get_mode(get(param, fit)),digits), ")\\newline $\\pm$ ",
    round(sd(get(param,fit)),digits), sep="")
}

print_heritability_table <- function(digits){
  #' `digits` is the number of significant digits
  #' Prints tabularx-table of heritability with posterior mean, posterior mode
  #' and standard deviation. Does it for logit, probit and Gaussian.
  header = paste( "% TABLE FROM R:", format(Sys.time(), "%a %b %d %X %Y"), "\n",
  "\\begin{table}[ht]\\centering\n",
    "\\begin{tabularx}{\\textwidth}{lXXX}\n",
    "\\hline\n",
    " & Binomial logit & Binomial probit & Gaussian  \\\\ \n",
    "\\hline \n"
  )
  main = paste(
    "Latent &", print_one_metric(fit.inla.logit, "h2.latent", digits),
    "&", print_one_metric(fit.inla.probit, "h2.latent", digits),
    "&", print_one_metric(fit.inla.gaussian, "h2.latent", digits),
    "\\\\ \n",
    "Scaled &", print_one_metric(fit.inla.logit, "h2.scaled", digits),
    "&", print_one_metric(fit.inla.probit, "h2.scaled", digits),
    "& --",
    "\\\\ \n",
    "QGglmm &", print_one_metric(fit.inla.logit, "h2.qgglmm", digits),
    "&", print_one_metric(fit.inla.logit, "h2.qgglmm", digits),
    "& -- \n"
  )
  footer = paste("\\end{tabularx}",
               "\\caption{<Insert caption>}",
               "\\label{tab:heritabily gutta}",
               "\\end{table}", sep="\n")

  cat(header, main, footer,sep="\n")
  # # Old attempt trying to make it a bit more flexible
  # out = c()
  # # Deal with latent first
  # out[1] = print_one_metric(fit, "h2.latent", digits)
  # param_names = c("h2.scaled", "h2.qgglmm")
  # for(i in 2:3){
  #   if('fit.inla.gaussian' != deparse(substitute(fit))){
  #     out[i] <- print_one_metric(fit,param_names[i-1], digits)
  #   }
  #   else{
  #     # Special case for Gaussian model since it
  #     # doesn't have any transformed variables
  #     out[i] <- "--"
  #   }
  # }
  # return(cat(out, "\\\\"))
}
print_heritability_table(4)

```

# Simulation data

```{r}

simulated.heritability <- function(NeNc=0.5, idgen=100, nGen = 9, sigmaA=0.4,
                                   linear.predictor=NA, simulated.formula=NA){
  #' Generate pedigree, fit gaussian (INLA) model and 
  #' Remark: linear.predictor should be a callable and pass (at least) u
  #' 
  #' Input:
  #' NeNc:    Effective/Census population mean, used to determine
  #'          Number of fathers and mothers per generation,
  #' idgen:   Numer of individuals per generation in pedigree
  #' nGen:    Number of generations in pedigree
  #' sigmaA:  Additive genetic variance (to get breeding values)
  #' 
  #' linear.predictor:  Callable function of 'u' (breeding values),
  #'                    Should be centered around 0
  #' simulated.formula: Formula expression using the response name
  #'                    `simulated.response`, param `id` and `Cmatrix`,
  #'                    all of which are defined locally in this method.
  #' Output:
  #' heritability:  Posterior latent heritability samples (no transformation)
  #' summary:       List of mean and quantiles of posterior heritability
  #' p:             Portion of TRUE observations in simulated response
  
  ped0 <- generatePedigree(nId = idgen, nGeneration = nGen, 
                           nFather = idgen * NeNc, nMother = idgen * NeNc)
  # Set correct format for pedigree
  pedigree <- ped0[ , c(1,3,2)]
  names(pedigree) <- c("id", "dam", "sire")
  pedigree <- ped0[ ,1:3]
  
  # Generate random breeding values
  # The following will CRASH if you don't use the patched MCMCglmm package!
  u <- rbv(pedigree, sigmaA)
  
  simulated.d.ped <- nadiv::prepPed(pedigree)
  simulated.Cmatrix <- nadiv::makeAinv(simulated.d.ped)$Ainv 
  
  # Generating "true" y_i
  
  # sigmoid.scale <- function(x) exp(x)/(exp(x)+1)
  # simulated.response <- rbinom(length(u), size=1,
  #                              prob=sigmoid.scale(linear.predictor(u)))
  
  # This assumes mean of \eta_i is 0
  simulated.response <- ifelse(linear.predictor(u) <= 0, 0, 1)
  p = mean(simulated.response) # portion of true responses
  
  # Model fitting LMM for binary trait
  # First reload formula environment to access local variables
  environment(simulated.formula) <- environment()
  simulated.fit.inla = inla(formula=simulated.formula, family="gaussian",
                             data=simulated.d.ped,
                             control.compute=list(dic=T)
                            )
  # Checks for error status in INLA fit,
  stopifnot(simulated.fit.inla$mode$mode.status == 0) # status != 0 is trouble
  
  heritability = get.h2(simulated.fit.inla, 10000) #10k samples should be suff
  list(
    heritability=heritability,
    summary=list(
      mean=mean(heritability), standard.deviation=sd(heritability),
       quantiles=quantile(heritability, probs=c(0.025, 0.5, 0.975))),
    p=p
  )
}



```

Now we try to run it through the model pipeline:

```{r}

simulated.formula = simulated.response ~ f(id,model="generic0",
    Cmatrix=simulated.Cmatrix,
    constr = F, # Shouldn't matter
    hyper=list(
      prec=list(initial=log(1/10), prior="pc.prec",param=c(1,0.05)) # PC priors
    ))

result = simulated.heritability(linear.predictor=function(u) u+rnorm(length(u)),
                       simulated.formula=simulated.formula, sigmaA=0.1)

threshold.scaling.param <- function(p) p*(1-p)/(dnorm(qnorm(p)))^2
threshold.scaled.h2 <- 1/threshold.scaling.param(result$p) * result$heritability
simulation.h2.true <- 10/(10+1) # Based on linear predictor, e.g. sigmaA/(sigmaA+1)
data.frame(True=simulation.h2.true,
           Mean.Threshold.scale = mean(threshold.scaled.h2),
           Confidence.Interval = paste0("(",
                            paste(
                              format(
                                quantile(threshold.scaled.h2,
                                         probs=c(0.025,0.975)),
                                digits=4),
                              collapse=", "),
                            ")"
                            ),
           Latent.Mean = mean(result$summary$mean)
           )

### It doesn't seem like it works so well for larger sigmaA's. Let's quantitatively look into deviation:
plot.h2.deviation <- function(){
  sigmaA.list <- c(1:10 %o% 10^(-3:3)) # Log scale between 10^-3 to 10^3
  deviation = c()
  estimates = c()
  true.vals = c()
  for(sigmaA in sigmaA.list){
    cat(">")
    result = simulated.heritability(
      linear.predictor=function(u) u+rnorm(length(u)),
      simulated.formula=simulated.formula, sigmaA=sigmaA)
    threshold.scaled.h2 <- 1/threshold.scaling.param(result$p) * result$heritability
    simulation.h2.true <- sigmaA/(sigmaA+1) # Based on linear predictor, e.g. sigmaA/(sigmaA+1)
    true.vals = c(true.vals, simulation.h2.true)
    estimates = c(estimates, mean(threshold.scaled.h2))
    deviation = c(deviation, simulation.h2.true-mean(threshold.scaled.h2))
  }
  data.frame(estimates=estimates, deviation=deviation,
             true.vals=true.vals, sigmaA=sigmaA.list)
}
res = plot.h2.deviation()
ggplot(data=res, aes(x=sigmaA)) +
  geom_line(aes(y=true.vals,color="True h^2")) +
  geom_line(aes(y=estimates, color="Fitted h^2")) +
  xlab(TeX("$\\sigma^2$")) + ylab(TeX("$h^2$")) + 
  scale_x_continuous(trans='log10') +
  scale_color_manual(name="True versus fitted heritability",
    breaks=c("True h^2", "Fitted h^2"),
    values = c("True h^2"='darkred', "Fitted h^2"='steelblue')
    )

simulation.hyperparameters <- function(NeNc_list=0.1, sigmaA_list=0.4){
  p = list()
  if(length(NeNc_list) > 1){
    cat("Running simulations for NeNc values, sigmaA is fixed at", sigmaA_list[1])
    for(NeNc in NeNc_list){
      simulation_results = simulated.heritability(
      NeNc=NeNc, idgen= 100, nGen = 10, sigmaA = sigmaA_list,
      linear.predictor = function(u) u+rnorm(length(u)),
      simulated.formula = simulated.formula
      )
      p[[paste0(NeNc)]] = simulation_results$heritability
    }
  }
  else{
    cat("Simulations for sigmaA, NeNc is fixed at", NeNc_list[1])
    for(sigmaA in sigmaA_list){
      cat("(",sigmaA,"),")
      simulation_results = simulated.heritability(
      NeNc=NeNc_list, idgen= 100, nGen = 10, sigmaA = sigmaA,
      linear.predictor = function(u) u+rnorm(length(u)),
      simulated.formula = simulated.formula
      )
      p[[paste0(sigmaA)]] = simulation_results$heritability
    }
  }
  return(p)
}

p = simulation.hyperparameters(NeNc_list = c(0.05, 0.1, 0.25, 0.5))
p2 = simulation.hyperparameters(sigmaA_list=c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75)*100)

par(mfrow=c(2,2))
for(i in names(p)){
  truehist(get(i,p), xlab=paste("NeNc =",i))
  abline(v=0.4)
}
par(mfrow=c(3,2))
for(i in names(p2)){
  truehist(get(i,p2), xlab = paste("sigmaA =", i))
  cat("True h2", as.numeric(i)/(as.numeric(i)+1), "\n")
  # abline(v=i/(as.numeric(i)+1)) # a+e_i, e_i~N
}

```
