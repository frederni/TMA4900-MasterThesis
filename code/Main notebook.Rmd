---
title: "Main notebook"
output: pdf_document
date: '2023-02-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Acknowledgements

The data and a large portion of data preprocessing is provided by Jane Reid. The re-implementation into INLA is also largely based on the work from Stefanie Muff.

# Data loading

```{r data loading}
library(MCMCglmm)
library(MASS)
library(nadiv)
library(bdsmatrix)
library(INLA)
library(QGglmm)
# library(SMisc)
library(ggplot2)
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!require("GeneticsPed", quietly = TRUE))
    BiocManager::install("GeneticsPed")
if (!require("MCMCglmm", quietly = TRUE))
    install.packages("../MCMCglmm-rbv-patch.tar.gz")

library("GeneticsPed") 
library("MCMCglmm")


qg.data.gg.inds <- read.table("../data/qg.data.gg.inds.steffi.txt", header=T)
d.ped <- ped.prune.inds <- read.table("../data/ped.prune.inds.steffi.txt", header=T)
d.Q <-  read.table("../data/Q.data.steffi.txt", header=T)

qg.data.gg.inds$natalyr.id <- qg.data.gg.inds$natalyr.no

```

Scaling continuous variances can be more stable: (I think?)

```{r}
qg.data.gg.inds$f.coef.sc <- scale(qg.data.gg.inds$f.coef,scale=FALSE)
qg.data.gg.inds$g1.sc <- scale(qg.data.gg.inds$g1,scale=FALSE)
qg.data.gg.inds$natalyr.no.sc <- scale(qg.data.gg.inds$natalyr.no,scale=FALSE)
qg.data.gg.inds$brood.date.sc <- scale(qg.data.gg.inds$brood.date,scale=FALSE)
```

The sex covariate is either `1` or `2`, so we binarize this covariate:

```{r}
qg.data.gg.inds$sex <- qg.data.gg.inds$sex.use.x1 - 1 
```

## Deriving *A*

In order to derive the A matrix, we need to work a bit

```{r}
d.ped <- nadiv::prepPed(d.ped)
```

In particular, for INLA we need ids that run from 1 to the number of individuals

```{r}
d.ped$id <- 1:(nrow(d.ped))
```

Need a map file to keep track of the ids

```{r}
d.map <- d.ped[,c("ninecode","id")]
d.map$g1 <- d.Q[match(d.map$ninecode,d.Q$ninecode),"g1"]
d.map$foc0 <- d.Q[match(d.map$ninecode,d.Q$ninecode),"foc0"]
```

Give mother and father the id

```{r}
d.ped$mother.id <- d.map[match(d.ped$gendam, d.map$ninecode),"id"]
d.ped$father.id <- d.map[match(d.ped$gensire, d.map$ninecode),"id"]
```

Make the inverse A matrix using the `nadiv` package:

```{r}
Cmatrix <- nadiv::makeAinv(d.ped[,c("id","mother.id","father.id")])$Ainv
```

Store the id twice: Once for the breeding value, and once for the independent residuals u with variance 1 (the latter are not going to be included in the end, but we checked what happened when they were there)

```{r}
qg.data.gg.inds$id <- d.map[match(qg.data.gg.inds$ninecode, d.map$ninecode), "id"]
qg.data.gg.inds$u <- 1:nrow(qg.data.gg.inds)
```

# INLA

The general INLA formula is provided below, where `f()` encode the random effect:

```{r}

formula.inla.scaled = surv.ind.to.ad ~ f.coef.sc + g1.sc + natalyr.no.sc + brood.date.sc + sex +
  f(nestrec, model="iid",hyper=list(
    prec=list(initial=log(1/0.05), prior="pc.prec",param=c(1,0.05)) # PC priors
  )) +
  f(natalyr.id, model="iid",hyper=list(
    prec=list(initial=log(1/0.25), prior="pc.prec",param=c(1,0.05)) # PC priors
  )) +
  f(id,model="generic0", # Here we need to specify the covariance matrix 
    Cmatrix=Cmatrix,     #    via the inverse (Cmatrix)
    constr = F, # Doesn't really matter
    hyper=list(
      prec=list(initial=log(1/10), prior="pc.prec",param=c(1,0.05)) # PC priors
     ))  # + # this last part is only needed if the u~N(0,1) residuals are included
# f(u, model="iid",
#   constr=TRUE,
#   hyper=list(
#     prec=list(initial=log(1), fixed=TRUE) # Fixed variance to 1
#   )) # This last component adds the independent residuals with variance 1;
```

Now we call INLA models, this is the slowest part:

```{r}

fit.inla.probit = inla(formula=formula.inla.scaled, family="binomial",
                       data=qg.data.gg.inds,
                       control.compute=list(dic=T, return.marginals.predictor=T),
                       control.family = list(link = "probit"),
)

fit.inla.logit = inla(formula=formula.inla.scaled, family="binomial",
                      data=qg.data.gg.inds,
                      control.compute=list(dic=T, return.marginals.predictor=T),
                      control.family = list(link = "logit"),
                      control.predictor = list(compute=T)
)

fit.inla.gaussian = inla(formula=formula.inla.scaled, family="gaussian",
                             data=qg.data.gg.inds,
                             control.compute=list(dic=T, cpo=T) 
)
```

A quick rundown of the `control` parameters we need. For the binomial models, we want to be able to use `QGglmm` and average over all fixed effects. This is done by supplying the *latent marginal predicted values*, which are not computed unless you pass the `control.compute` argument in the call, with this maringals predictor thing. We also want to compute CPO in the Gaussian model so we can look a bit at its "residuals" (PIT values). The last ones are:

* `control.family` provides link function
* `control.compute` with dic computes deviance information criteria which can be compared for the different models.


## Residual analyses on Gaussian model

For the Gaussian INLA model we also compute PIT. From example (don't copy this!) "The PIT is the probability of a new response less than the observed response using a model based on the rest of the data. We'd expect the PIT values to be uniformly distributed if the model assumptions are correct." [From here](https://julianfaraway.github.io/brinla/examples/chicago.html).

The first plot obviously shows a non-linear trend but rather a sigmoid-like curve. This is interesting!

The second plot shows the fitted values as a function of PIT. Not sure how it should look like, but definitely not like this!

The third plot is the posterior means of the linear predictor for the Gaussian fit versus the same value for the probit model. If we compare logit to probit we see pretty close to a one-to-one correspondance. This is completely violated when comparing the Gaussian one to the two other models.

```{r}
# TODO with these plots: Make them to ggplots instead so it's the same style (aesthethic) for all plots...

# Residual analysis on Gaussian INLA object:)
pit.g = fit.inla.gaussian$cpo$pit

# <Plot 1> Analogous to QQ-plot so should be linear
# --------
plot(
  (1:length(pit.g))/(length(pit.g)+1), sort(pit.g), xlab="Quantiles",
  ylab="Sorted PIT values", main="Sorted PIT values for Gaussian model"
)

# <Plot 2> Posterior mean fitted values as a function of PIT values
# --------    analagous to "Residuals vs fitted"
plot(fit.inla.gaussian$summary.fitted.values$mean, pit.g,
     xlab="Posterior mean fitted values",
     ylab="PIT values", main="Posterior mean vs. PIT values"
     )

# <Plot 3> Mean linear predictor of different models, showing 
# --------    how different predictors for the models are
par(mfrow=c(1,3))
plot(fit.inla.logit$summary.linear.predictor[, 1],
     fit.inla.probit$summary.linear.predictor[, 1],
     main="\nLogit (x) versus Probit (y)", xlab="",ylab=""
)
abline(0,1)
plot(fit.inla.gaussian$summary.linear.predictor[, 1],
     fit.inla.probit$summary.linear.predictor[, 1],
     main="\nGaussian (x) versus Probit (y)", xlab="", ylab=""
)
abline(0,1)
plot(fit.inla.gaussian$summary.linear.predictor[, 1],
     fit.inla.logit$summary.linear.predictor[, 1],
     main="\nGaussian (x) versus Probit (y)", xlab="", ylab=""
)
abline(0,1)
mtext("Mean linear predictor of the different models",
      side = 3, line = -1, outer = TRUE)

# <Plot 4> Plot of 'residuals', i.e. difference in true data and the 
# --------    50% quantile of the fitted values

# Compute residuals from the 50% quantile of fitted values
# Scale residuals by multiplying the square of the precisions? Currently: no scaling
n.obs = length(qg.data.gg.inds$u)
resids = qg.data.gg.inds$surv.ind.to.ad -
  fit.inla.gaussian$summary.fitted.values$`0.5quant`
par(mfrow=c(1,1))
plot(resids, main="Residuals of Gaussian model", ylab="")

# <Plot 5> Recreation of QQ plot using residuals computed above instead of PIT values
qqplot(qnorm(ppoints(n.obs),
             mean = mean(qg.data.gg.inds$surv.ind.to.ad),
             sd = sd(qg.data.gg.inds$surv.ind.to.ad)
             ),
       resids, xlab="Theoretical quantiles", ylab="Sample Quantiles",
       main="Q-Q plot from 'residuals' above")

# <From that thing>
ggplot(data.frame(
  Fittedvalues = fit.inla.gaussian$summary.fitted.values$mean,
  Residuals = resids),
  aes(x=Fittedvalues, y=Residuals)) +
  geom_point() + geom_smooth(se=T) +
  labs(x="Fitted values", title="Violation of linearity assumtption")

```

We define a general method for looking at the results of an INLA model.

```{r}
## This is a nice place to play around
test = fit.inla.logit$marginals.linear.predictor
lapply(test, mean)
plot(test$Predictor.2) # 43x2 data for x and y...

inla.posterior.marginal.latent.mode <- function(fit){
  modes = c()
  iter = 1
  for(predictor in names(fit$marginals.linear.predictor)){
    xy = get(predictor, fit$marginals.linear.predictor)
    modes[iter] = xy[, "x"][which.max(xy[, "y"])]
    iter = iter + 1
  }
  modes
}

report.max.skewness <- function(posterior){
  #' Made esepcially for marginal linear predictor but should work on any
  #' list containing named "x" and "y" columns
  library(e1071)
  iter = 1
  posterior_skews = c()
  for(predictor in names(posterior)){
    posterior_skews[iter] = skewness(get(predictor, posterior)[, "x"])
    iter = iter + 1
  }
  cat("Minimum skew for list no.", which.min(posterior_skews), "with skewness",
      min(posterior_skews), "and max for list no.", which.max(posterior_skews),
      "with skewness", max(posterior_skews), ".\n")
}

report.max.skewness(test)
plot(test$Predictor.321)


analyze.inla.fit <- function(inla.fit){
  # Collecting diagnostic functions in this method:-)
  #' Check if there is a problem (ok of =0) and dic
  print(paste(inla.fit$mode$mode.status,
  inla.fit$dic$dic))
  
  print(summary(inla.fit))
  
  #inla.fit$summary.hyperpar,
  #inla.fit$summary.fixed,
  
  #inla_mmarginal(inla.fit),
  #inla_emarginal(inla.fit)
  #))
  
  #' Plotting the posterior marginals for the variances; This is a bit cumbersome,
  #' because INLA works with precisions, so we need a transformation. 
  #' The code below does it for us:
  par(mfrow=c(1,3))
  
  plot(inla.tmarginal(
    function(x) 1/x,inla.fit$marginals.hyperpar$`Precision for nestrec`),
    type="l",main = "next")
  
  plot(inla.tmarginal(
    function(x) 1/x,inla.fit$marginals.hyperpar$`Precision for natalyr.id`),
    type="l",main="natalyr")
  
  plot(inla.tmarginal(
    function(x) 1/x,inla.fit$marginals.hyperpar$`Precision for id`),
    type="l",main="animal")
}

# analyze.inla.fit(fit.inla.probit)

```

Below is a method used to obtain posterior distribution of the back-transformed heritability:

```{r}
get.h2 <- function(inla.fit, n, use.scale=F, model=NA){
  #' Get n samples of heritability from INLA fit
  #' h^2 computed as reciprocal of precision for id, over the sum of 
  #' (the reciprocal of) all random effects / hyperparameters 
  samples <- inla.hyperpar.sample(n=n,inla.fit)
  denominator = 0
  for(cname in colnames(samples)){ denominator = denominator + 1/samples[, cname]}
  
  if(use.scale){
    # We need model specification to use scale
    stopifnot(model %in% c("binom1.probit", "binom1.logit"))
    scale.param = ifelse(model == "binom1.probit", 1, pi^2/3)
    denominator = denominator + scale.param
  }
  
  h2.inla <- (1/samples[,"Precision for id"]) / denominator
  return(h2.inla)
}

get.h2.from.qgparams <- function(inla.fit, modelname, n, n.obs=nrow(d.ped)){
  #' Computes a posterior of data-scale heritability (h2) using QGParams
  #'  
  #' Params:
  #' inla.fit    the fitted INLA object
  #' modelname  a string specifying model
  #'    ("Gaussian", "binomN1.probit", "binom1.logit")
  #' n.obs      keyword argument if binomial model is has N != 1 trials
  #'    NB: Should explicitly be set to NULL if not relevant (Gaussian model)
  #'    Currently not in use as we're always dealing with binary (1 trial)
  stopifnot(modelname %in% c("Gaussian", "binom1.probit", "binom1.logit"))
  samples.posterior <- inla.hyperpar.sample(n=n,inla.fit)
  vp.samples = 0
  for(cname in colnames(samples.posterior)){
    vp.samples = vp.samples + 1/samples.posterior[, cname]
    }
  mu = inla.fit$summary.fixed$mean[1]
  va.samples = 1/samples.posterior[,"Precision for id"]
  kwargs = list(verbose=F)
  # out = mapply(QGparams, mu, va.samples, vp.samples, modelname, MoreArgs = kwargs)
  h2.getter = function(...){
    cat(...)
    get("h2.obs", suppressWarnings(QGparams(...)))
    }
  out = mapply(h2.getter, mu, va.samples, vp.samples, modelname, MoreArgs=kwargs)
  return(out)
}


new.h2.transf <- function(fit, modelname, nsamples){
  # This is very much WIP but works I think now
  posterior.samples = inla.hyperpar.sample(nsamples, fit)
  marginal.mode = inla.posterior.marginal.latent.mode(fit)
  debug_mu = fit$summary.fixed$mean[1]
  vp.samples = 0
  for(cname in colnames(posterior.samples)){
    vp.samples = vp.samples + 1/posterior.samples[, cname]
    }
  df <- data.frame(va = as.vector(1/posterior.samples[, "Precision for id"]),
                   vp = as.vector(vp.samples)
                   )
  posterior = do.call("rbind", apply(df, 1, function(row){
    QGparams(predict=marginal.mode, mu=debug_mu, var.a=row[["va"]], var.p=row[["vp"]],
             model=modelname, verbose=F)
  }))
  posterior
}

t_before = Sys.time()
transformed_heritability = new.h2.transf(fit.inla.logit, "binom1.logit", 1000)
heritability_no_fixed_effect_fix = get.h2.from.qgparams(fit.inla.logit, "binom1.logit", 1000)
cat("Time elapsed with rbind:", Sys.time()-t_before, "mins")
t_before = Sys.time()

{
par(mfrow=c(1,2))
truehist(transformed_heritability$h2.obs, xlab=expression(h[obs]^2), 
         main="Averaging over fixed effects")
truehist(heritability_no_fixed_effect_fix, xlab=expression(h[obs]^2),
         main="No averaging")
}

```

We extend the contents of the INLA fit to include heritabilities on the different scales

```{r}
# Compute h2
n.samples = 10000
fit.inla.gaussian$h2.latent = get.h2(fit.inla.gaussian, n.samples)
fit.inla.logit$h2.latent = get.h2(fit.inla.logit, n.samples)
fit.inla.probit$h2.latent = get.h2(fit.inla.probit, n.samples)

fit.inla.logit$h2.scaled = get.h2(fit.inla.logit, n.samples, use.scale=T,
                                  model="binom1.logit")
fit.inla.probit$h2.scaled = get.h2(fit.inla.probit, n.samples,use.scale=T,
                                   model="binom1.probit")

fit.inla.logit$h2.qgglmm  = get.h2.from.qgparams(fit.inla.logit, "binom1.logit", n.samples)
fit.inla.probit$h2.qgglmm = get.h2.from.qgparams(fit.inla.probit, "binom1.probit", n.samples)
```

Plotting some histograms:

Trying one with all overlapping:

```{r}
df.latent.h2 = data.frame(samples=c(unname(fit.inla.logit$h2.latent), unname(fit.inla.probit$h2.latent)),
                      Model=c(
                        rep("Logit",length(fit.inla.logit$h2.latent)),
                        rep("Probit",length(fit.inla.probit$h2.latent))
                      )
                        )

ggplot(df.latent.h2, aes(x=samples, fill=Model)) +
  geom_density(alpha=0.5) +
  ggtitle("Posterior of latent scale heritability for binomial INLA models") +
  xlab("(Latent-scale) Heritability") +
  ylab("Density")
```

```{r}
df.transformed.h2 = data.frame(
  samples=c(
    unname(fit.inla.logit$h2.qgglmm),
    unname(fit.inla.probit$h2.qgglmm),
    unname(fit.inla.gaussian$h2.latent)
    ),
  Model=c(
    rep("Logit",length(fit.inla.logit$h2.qgglmm)),
    rep("Probit", length(fit.inla.probit$h2.qgglmm)),
    rep("Gaussian (no transformation)",length(fit.inla.gaussian$h2.latent))
    )
  )

ggplot(df.transformed.h2, aes(x=log(samples), fill=Model)) +
  geom_density(alpha=0.5) +
  ggtitle("Posterior of transformed heritability") +
  xlab("(Latent-scale) Log-heritability") +
  ylab("Density")


```

Let's try to make table dynamic:

```{r}
get_mode <- function(vec){
  d = density(vec)
  d$x[which.max(d$y)]
}

model.name = unlist(strsplit("test.hei", "[.]"))[2]


print_one_metric <- function(fit, param, digits){
  cat(
    round(mean(get(param, fit)),digits), " (",
    round(get_mode(get(param, fit)),digits), ")\\newline $\\pm$ ",
    round(sd(get(param,fit)),digits), sep="")
}

print_heritability_table <- function(digits){
  #' `digits` is the number of significant digits
  #' Prints tabularx-table of heritability with posterior mean, posterior mode
  #' and standard deviation. Does it for logit, probit and Gaussian.
  header = cat( "% TABLE FROM R:", format(Sys.time(), "%a %b %d %X %Y"), "\n",
  "\\begin{table}[ht]\\centering\n",
    "\\begin{tabularx}{\\textwidth}{lXXX}\n",
    "\\hline\n",
    " & Binomial logit & Binomial probit & Gaussian  \\\\ \n",
    "\\hline \n"
  )
  main = cat(
    "Latent &", print_one_metric(fit.inla.logit, "h2.latent", digits),
    "&", print_one_metric(fit.inla.probit, "h2.latent", digits),
    "&", print_one_metric(fit.inla.gaussian, "h2.latent", digits),
    "\\\\ \n",
    "Scaled &", print_one_metric(fit.inla.logit, "h2.scaled", digits),
    "&", print_one_metric(fit.inla.probit, "h2.scaled", digits),
    "& --",
    "\\\\ \n",
    "QGglmm &", print_one_metric(fit.inla.logit, "h2.qgglmm", digits),
    "&", print_one_metric(fit.inla.logit, "h2.qgglmm", digits),
    "& -- \n"
  )
  footer = cat("\\end{tabularx}",
               "\\caption{<Insert caption>}",
               "\\label{tab:heritabily gutta}",
               "\\end{table}", sep="\n")

  cat(header, main, footer,sep="\n")
  # # Old attempt trying to make it a bit more flexible
  # out = c()
  # # Deal with latent first
  # out[1] = print_one_metric(fit, "h2.latent", digits)
  # param_names = c("h2.scaled", "h2.qgglmm")
  # for(i in 2:3){
  #   if('fit.inla.gaussian' != deparse(substitute(fit))){
  #     out[i] <- print_one_metric(fit,param_names[i-1], digits)
  #   }
  #   else{
  #     # Special case for Gaussian model since it
  #     # doesn't have any transformed variables
  #     out[i] <- "--"
  #   }
  # }
  # return(cat(out, "\\\\"))
}
print_metrics(4)

```

# Simulation data

```{r}


# set a value for the Ne/Nc ratio
# here is 0.5 but it can be set to 0.15 or 0.05
#Ne : Effective population size
#'    determines the rates of genetic drift, loss of neutral genetic diversity
#'    and increase in inbreeding experienced by a population.
#Nc : Census population size
#'    affects the degree of demographic stochasticity,
#'    and is used to assess threat status.
#'    See [here](
#'    https://onlinelibrary.wiley.com/doi/full/10.1111/j.1095-8649.2011.03124.x
#'    )
#'    and [here](
#'    https://onlinelibrary.wiley.com/doi/full/10.1111/j.1095-8649.2011.03124.x
#'    )
#'    

simulated.heritability <- function(NeNc=0.5, idgen=100, nGen = 9, sigmaA=0.4,
                                   linear.predictor=NA, simulated.formula=NA){
  # Remark: linear.predictor should be a callable and pass (at least) u
  # generate the pedigree using the function generatePedigree from GeneticsPed
  # nFather and nMother are the number of fathers and mothers per generation
  # they are generated according to the selected Ne/Nc ratio
  ped0 <- generatePedigree(nId = idgen, nGeneration = nGen, 
                           nFather = idgen * NeNc, nMother = idgen * NeNc)
  # set correct format for pedigree
  pedigree <- ped0[ , c(1,3,2)]
  names(pedigree) <- c("id", "dam", "sire")
  # generate breeding values (always constant)
  
  # using the function rbv from MCMCglmm
  # fix the additive variance value, here is 0.4 but it can be any value
  sigmaA <- 0.4
  pedigree <- ped0[ ,1:3]
  # The following will CRASH if you don't use the patched MCMCglmm package!
  u <- rbv(pedigree, sigmaA) # Breeding values for each individual
  
  simulated.d.ped <- nadiv::prepPed(pedigree)
  simulated.Cmatrix <- nadiv::makeAinv(simulated.d.ped)$Ainv 
  
  # Generating "true" y_i
  sigmoid.scale <- function(x) exp(x)/(exp(x)+1)
  simulated.response <- rbinom(length(u), size=1,
                               prob=sigmoid.scale(linear.predictor(u)))
  
  # Model fitting LMM for binary trait
  # trying to re-load formula in the context of local variables
  environment(simulated.formula) <- environment()
  simulated.fit.inla = inla(formula=simulated.formula, family="gaussian",
                             data=simulated.d.ped,
                             control.compute=list(dic=T)
                            )
  # (debug) checking that INLA was able to fit model
  stopifnot(simulated.fit.inla$mode$mode.status == 0) # status != 0 is trouble
  
  heritability = get.h2(simulated.fit.inla, 10000) #10k samples should be suff
  list(
    heritability=heritability,
    summary=list(
      mean=mean(heritability), standard.deviation=sd(heritability),
       quantiles=quantile(heritability, probs=c(0.05, 0.5, 0.95)))
  )
}



```

Now we try to run it through the model pipeline:

```{r}

simulated.formula = simulated.response ~ -1 + # a_i (and residuals) only
  f(id,model="generic0",
    Cmatrix=simulated.Cmatrix,
    constr = F, # Shouldn't matter
    hyper=list(
      prec=list(initial=log(1/10), prior="pc.prec",param=c(1,0.05)) # PC priors
    ))

simulation_results = simulated.heritability(linear.predictor = function(u) u+rnorm(length(u)),
                       simulated.formula = simulated.formula)

truehist(simulation_results$heritability)

#' * Fix number individuals and Ne/Nc
#' * For different sigmaA (0.01, 0.05, 0.1, 0.25, 0.5, 0.75)
#' * Fit INLA model
#' * Compute h2
#' * Report on computed h2 (posterior mean) and true h2
#' * Try fixed sigmaA and varying Ne/Nc
```
