\chapter{Discussion} \label{sec:discussion}
The present discussion chapter aims to provide a critical review and comparison of the different scales of heritability estimates obtained using the different models. The results in the previous chapter provide the basis for discussion, where we specifically will evaluate the validity of the Gaussian model, its computational aspects, and whether a Gaussian model can be sufficient for heritability estimation. Included in the chapter is a section on future potential work in the same research domain. 

%% The following didn't fit anywhere...
% \textcite{reid2021} concluded that the additive genetic variance, $\sigma^2_A$ was either overestimated, or potentially something else contributes to decreased the mean phenotypic value. This because we're measuring juvnile survival which is very related to fitness.

\section{Gaussian estimates in simulation}
The overall results in \autoref{fig:simulation_h2_dev} show that the scaled heritability from the Gaussian model coincides well with the true heritability on the underlying scale. For lower values of $\sigma^2_A$ and hence $h^2$ (\autoref{fig:simulation_h2_dev:small}), both the scaled and unscaled plots seem to be close. However, when $h^2$ increases, it becomes more apparent that we need the threshold scaling.

One potential problematic component of the model specification in the simulation case is the choice of priors. In the model, the prior is chosen based on the true value for $\sigma^2_A$, ensuring a well-suited prior estimate. However, this may not reflect the degree of prior knowledge in most datasets, especially not in wild population surveys. To challenge this prior assumption, we performed two different simulations: one with a constant PC prior PC$(1,0.05)$ for all $\sigma^2_A$, and one case with PC$(U, 0.05)$ with $U=2\sigma^2_A$. Both simulations yielded results very similar to the varying priors explained in the methods chapter. % Another thing that may influence the performance of INLA-fitted models, is if we use full Laplace approximation or simplified Laplace approximation (see subsection 3.3.1). \autoref{sec:method:inla}.
Furthermore, we can also note that the binomial dichotomization shown in \autoref{fig:simulation_h2_dev:binom} seems to somewhat underestimate the underlying heritability, compared to the threshold dichotomization. The dichotomized values in this case are binomial realizations with success probability given by applying the normal cumulative density function ($\Phi$) to $\Tilde{\bm\eta}$, and this dichotomization choice introduces variance that would explain this result. One way to consider the introduced variance from binomial dichotomization is that the mapping from an underlying Gaussian distribution onto the binary traits is not exact and contributes to some unexplained variability. Thus, binomial dichotomization can represent the same as including residual variance in the denominator.
% For the latter case with rounding, we can quite easily obtain the variance introduced by rounding. Assuming that $\Tilde{\eta} \sim \mathcal N(0, \sigma^2)$ for an arbitrary $\sigma^2$, we define $v$ such that
% \begin{equation}
% v = 
% \begin{cases}
%     0, \quad \Tilde{\eta}\le0,\\
%     1,\quad \Tilde{\eta} > 0
% \end{cases} .
% \end{equation}
% Then,
% \begin{align}
% \operatorname{E}[v] &= 0 \cdot \operatorname{Pr}(v=0) + 1\cdot \operatorname{Pr}(v=1) \\
% &= \operatorname{Pr}(\Tilde{\eta}>0) \nonumber \\ 
% &= 1-\operatorname{Pr}(\Tilde{\eta}/\sigma \le0) \nonumber \\
% &=1-\Phi(0)=0.5. \nonumber
% \end{align}

% The variance of $v$ becomes
% \begin{align}
% \operatorname{Var}[v] &=\operatorname{E}[\left(v-\operatorname{E}(v)\right)^2] \\
% &=\operatorname{Pr}(v=0)(0-0.5)^2+\operatorname{Pr}(v=1)(1-0.5)^2 \nonumber\\
% &=0.25\quad\forall \sigma^2, \nonumber 
% \end{align}
% \todo{Unsure about the relevance of these computations.}
% which indicates that using rounding, although it introduces some dichotomization variance, should not be the source of any significant error in the simulation study.

\section{Interpretability on different scales}
%%% Part 2 of thesis discussion
This section will consider how the heritabilities obtained from the different scales relate to each other, aiming to answer whether one can use Gaussian regression instead of binomial regression. Recall that a summary of the different scales is provided in \autoref{tab:h2 notation}.

The first result to consider is the mean and mode of posterior heritability (Tables \ref{tab:heritability simulation} and \ref{tab:heritability application}). The means and modes have relatively little skewness, since the mean and mode are close to each other, although the mode is consistently lower than its corresponding mean. This can be attributed to some small positive skewness in all of the models.

We may also note that for the application data, the Gaussian $h^2_\text{obs}$ is less than one standard deviation away from the corresponding probit models on the observation scale, $h^2_\Psi$ and $h^2_\Phi$. The simulation data become more challenging to interpret. The underlying heritability would in our case be $0.5/(1+0.5)=\frac13$, assuming it follows a Gaussian distribution before dichotomization. In this case, the heritability from the Gaussian model transformed to the liability scale $h^2_\text{liab}$, along with the link variance transformation $h^2_\Phi$, provides estimates closest to the true value (see \autoref{tab:heritability simulation}). This is in line with what we expected, as the two heritability estimates have the same liability scale, whereas the others are on a different scale. Furthermore, solving for the theoretical $h^2_\text{obs}$ using the threshold model and the true value for $h^2_\text{liab}$, we obtain with the simulated \input{figures/trueh2discussion}
As expected, the Gaussian $h^2_\text{obs}$ and binomial back-transformed $h^2_\Psi$ are the closest, where the binomial model's mode is, to a small degree, closer to the true value than the Gaussian mode (\autoref{tab:heritability simulation}). Hence, it seems that the Gaussian model overestimates heritability, albeit to a small degree.
%Note that in the context of the simulation study, the latent scale heritability is found to be very close to $1$. This can be attributed to the presence of only two random effects, namely the breeding value and an iid random effect, which is estimated to be close to zero.

The figures supporting the heritability estimates from the tables are the figures of its posterior density (Figures \ref{fig:posterior simulation heritability} and \ref{fig:posterior application heritability}). Recall that $h^2_\Psi$ is more computationally intensive but also more precise than $h^2_\Phi$, which motivates comparing the precise $h^2_\Psi$ to the Gaussian model instead of $h^2_\Phi$. In addition, the liability scale for the Gaussian model should be equivalent to $h^2_\Phi$ \autocite{de2016general}.

Observing first the observation scale (Figures \ref{fig:posterior simulation heritability:observation} and \ref{fig:posterior application heritability:observation}), we can instantly remark that $h^2_\text{obs}$ and $h^2_{\Psi}$ are very similar. The Gaussian estimate is more positively skewed for the application data, but is generally very similar to $h^2_\Psi$ in terms of shape and numerical values. The simulation has a larger deviation between modes, as the probit one seems to be shifted towards the right. This is in line with our observations from the table summary. The liability scale for the Gaussian model is compared with $h^2_\Phi$ (Figures \ref{fig:posterior simulation heritability:liability} and \ref{fig:posterior application heritability:liability}), where we observe similar deviations, though with less skewness for the Gaussian model.

\subsection{Robustness of the models}

Robustness tests provide information on the performance of various models in estimating heritability on different scales. Based on the fixed effect Gaussian models for varying $\sigma^2_A$ (\autoref{fig:fixed effects sim deviance gaussian model}), the Gaussian model obtains estimates of underlying heritability that somewhat approximate the theoretical true value for a balanced phenotypic mean. However, heritability appears to be overestimated, especially in the case of an unbalanced phenotypic mean. Thus, it seems like the threshold model breaks down with a dominating fixed effect.

Additionally, the posterior density of heritability on the observation scale (\autoref{fig:fixedeffects probit vs gaussian}) suggests that both the binomial and Gaussian models struggle to accurately estimate heritability on the observation scale when a fixed effect dominates the linear predictor. In general, it is difficult to determine whether the back-transformed probit or the Gaussian model is the closest to the correct value in this result, as we have no true observation-scale heritability for reference. The true heritability (based on the chosen values for the other components of the linear predictor) is on a liability scale, and we cannot safely state that $\hat p$, the estimator for the marginal phenotypic mean $p$, is sufficient to approximate each conditional $p_i$. Recall that each dichotomized $y_i$ has its underlying probability $p_i$ and is dependent on the covariate for each individual $i$.

The difference between heritability from the back-transformed probit and Gaussian models appears to also be apparent in larger values of $\sigma^2_A$, though to a smaller degree with a balanced phenotypic mean (Figures \ref{fig:fixedeffects probit vs gaussian:hVAlP} and \ref{fig:fixedeffects probit vs gaussian:hVAhP}). When the magnitude of $\beta_\text{sex}$ for the fixed effect decreases, the proportion of total variance from fixed effects becomes smaller, meaning that we would expect the two heritability densities to be closer to the same value, which is confirmed in \autoref{fig:fixedeffects varying betas} in the appendix.

An important aspect that may explain the results is that the simulation only has one single, binary, and dominating fixed effect. As a consequence, the individual's response is directly associated with its covariate for the fixed effect. Had we used more fixed effects, effects with a smaller weight $\beta$ and perhaps continuous covariates, the inclusion of fixed effects may not lead to the same results as we have in our simulations. Supporting this idea are the results from the simulation work where the model uses several fixed effects, where the Gaussian model obtains heritability estimates close to the probit model with back-transformation (\autoref{fig:posterior application heritability}).

% In this figure, the probit model performs better for smaller heritability and hence small $\sigma^2_A$, whereas the Gaussian model is in some cases better for higher heritability values, particularly when the variance is around 500 or above (see \autoref{fig:posteriors fixed simulation} in the appendix). Furthermore, the distinct difference between the back-transformed probit model and the Gaussian model we see is not as apparent in either the simpler simulation cases or the application data with a series of fixed and random effects. A more detailed analysis of how much the variance in the simulation data's fixed effects predictors may be the next line of action to further understand this result. \todo{This par must be fixed}

% This is also difficult to clearly discuss, as different runs with the same variance settings can generate significantly different results. Regardless of run, the theoretical value seems to be between the mode from the binomial model as a lower limit, and the mode of the Gaussian one as an upper limit. 

The second aspect of robustness concerns overdispersion, and the results are provided in \autoref{fig:overdisperion plots}. However, the alternative probit model without any random iid effect results in almost exactly the same posterior density as a standard probit model (with an iid effect), for all combinations tested of $\sigma^2_A$ and $\sigma^2_E$. This indicates that the model with an iid parameter sends the iid parameter towards zero and attributes the overdispersion variance to the additive genetic variance instead. In the general simulation runs, we also include an iid term, where we see that $h^2_\text{lat}$ is very close to one, indicating that the iid effect goes towards zero for simulations as well. Although the probit model does not differ when including an iid term in its linear predictor, the Gaussian model generates observation-level heritability closely resembling the probit models for the four combinations of $\sigma^2_A$ and $\sigma^2_E$.

\section{Normality of Gaussian model}
%%% Normality of Gaussian model
The normality tests of the Gaussian model indicate that the residuals are far from normally distributed, clearly violating the model assumptions of a linear model (Figures \ref{fig:sorted pit values} to \ref{fig:gaussian residuals}). Violation of the model assumptions has consequences for further model inference, since, for example, the F-test is sensitive to the normal assumption \autocite{f-test-normality}. In general, models that violate their assumptions can also lead to more biased estimates, since the predictor in linear regression assumes Gaussian residuals with constant variance. If the residuals no longer have constant variance, the equivalence between the closed form solution \eqref{eq:theory:closed form linreg} and the maximum likelihood estimate also becomes violated. Thus, the estimates from the predictor and consequently variance and heritability estimates can also be subject to bias. This clear violation is here, however, expected, seeing as the model fits a binary phenotype as the response.

Another result in favor of using binomial regression is the deviance information criterion whose values are shown in Tables \ref{tab:simulation DICs} and \ref{tab:application DICs}. In both datasets, the binomial model has a significantly lower DIC value than the Gaussian equivalent. Note that we cannot compare DIC values across different datasets, as they should only be used in model selection. Thus, varying values between probit models for the different datasets are expected, and we cannot infer any conclusions from such a result.

Despite clear violations, we still see overall good performance from the Gaussian model. Therefore, the bias to additive genetic variance introduced by normality violation may not be severe enough to bias heritability. Since heritability is a ratio between variances, another possibility would be that the bias in $\sigma^2_A$ is somewhat counteracted by taking the ratio of total phenotypic and additive variance. These hypotheses are difficult to test for but can explain why the heritability bias in the Gaussian model is not larger. 

\section{Computational aspects}

%%% QGglmm with or without the predict argument
An important result highlighted in the back-transformation techniques on the application data (\autoref{fig:qgglmm application}), is that the simpler, yet faster method \textit{No averaging} yields results strikingly similar to the two slower methods averaging over fixed effects. Estimates deviate significantly more in the simulation case (\autoref{fig:qgglmm simulation}) when using a larger additive genetic variance.

As shown by the execution time of the methods in seconds (\autoref{tab:h2psi runtime}), the fastest technique (\textit{No averaging}) is more than six times faster than the most computationally demanding (\textit{Bayesian}). In the specific case of a binary probit model, the algorithm does not require numerical integration, meaning that all methods are sufficiently fast and we can use the method denoted by \textit{Bayesian}. If we had considered other link functions without a closed form back-transformation such as the logit link, the fastest method might be the only viable choice.

In general, the choice of fixed effects is expected to substantially change the heritability estimate \autocite{wilson2008}, in line with the results of the simulation with sufficiently high $\sigma^2_A$, but contradictory to our results for the application data. We fit our models in a Bayesian statistical context, and other modeling frameworks can yield different results. In addition, \textcite{qgglmmguide2020} shows a case study in which averaging changes the observation-scale heritability from about $0.3$ without averaging, to $0.2$ with averaging. Thus, we cannot state that one does not need the process of averaging over fixed effects in general. The results also show that for sufficiently large $\sigma^2_A$, the different densities of $h^2_\Psi$ will deviate more from one another (\autoref{fig:qgglmm simulation:bigvA}). Lastly, we have not tested different values for the hyperparameter $w$, the integration width in \autoref{alg:qgglmm}. With a smaller $w$, the integrals are evaluated over a smaller space, which would yield more accurate results assuming it would not increase the numerical integration error. However, for the case of binary probit, $w$ is not used and thus is not taken into account.                    

\section{Further work}
The robustness tests indicate that including fixed effects in the denominator may be appropriate. However, the tests do not clarify which cases it is necessary to include variance from fixed effects, seeing as the application data provides accurate estimates without including variance from fixed effect in the heritability estimation. Another shortcoming of the findings is to what extent we can generalize the results of the robustness tests. Although we have tested some extensions, the simulation datasets do not introduce complex animal models with several fixed effects. An alternative approach would be to fit two animal models without fixed effects, one with the data for $\bm x_\text{sex}=0$, and the latter with $\bm x_\text{sex}=1$. Then, one would expect, for a sufficiently large sample size, that the heritability would be similar.

Another aspect worth considering is modeling with a more unbalanced response variable. For example, looking at models whose binary trait is highly unbalanced ($p < 0.1$), could provide insight into limitations to the Gaussian model, as suggested in \textcite{vanvleck1972}. Furthermore, some animal models may also have generous use of interaction terms in the model statements, which has neither been discussed nor included in this thesis.
Also, note that a deliberate limit in the thesis was made by assuming that heritability is the most important metric when analyzing wild populations. However, heritability has been subject to scrutiny and some claim that other measurements related to additive genetic variance can be more appropriate, such as evolvability \autocite{hansen2011}.

Finally, in wild population studies, missing data tend to be more prevalent compared to the datasets used in this thesis. For the simulation case, we have an artificially complete pedigree. For our song sparrow data, we also have a complete pedigree that is not comparable to most wild population survey data. In a further study, it could be interesting to see how missing data and sensitivity to pedigree errors can influence Gaussian heritability estimates, for instance, by applying a capture-recapture animal model \autocite{papaix2010combining}.